<!DOCTYPE html><html lang="en-US" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="DETR End-to-End Object Detection with Transformers" /><meta name="author" content="darkknightzh" /><meta property="og:locale" content="en_US" /><meta name="description" content="仅供学习交流使用，错误之处在所难免，欢迎指正." /><meta property="og:description" content="仅供学习交流使用，错误之处在所难免，欢迎指正." /><link rel="canonical" href="https://darkknightzh.github.io/posts/DETR/" /><meta property="og:url" content="https://darkknightzh.github.io/posts/DETR/" /><meta property="og:site_name" content="darkknightzh" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-08-21T09:23:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="DETR End-to-End Object Detection with Transformers" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"darkknightzh"},"dateModified":"2021-09-27T18:57:55+08:00","datePublished":"2021-08-21T09:23:00+08:00","description":"仅供学习交流使用，错误之处在所难免，欢迎指正.","headline":"DETR End-to-End Object Detection with Transformers","mainEntityOfPage":{"@type":"WebPage","@id":"https://darkknightzh.github.io/posts/DETR/"},"url":"https://darkknightzh.github.io/posts/DETR/"}</script><title>DETR End-to-End Object Detection with Transformers | darkknightzh</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] }, // chtml: { displayAlign: 'left' } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/avatar.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">darkknightzh</a></div><div class="site-subtitle font-italic">忘记一个人，从忘记那个声音开始</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>主页</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>时间轴</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/darkknightzh" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['',''].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>DETR End-to-End Object Detection with Transformers</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>DETR End-to-End Object Detection with Transformers</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> darkknightzh </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, Aug 21, 2021, 9:23 AM +0800" prep="on" > Aug 21, 2021 <i class="unloaded">2021-08-21T09:23:00+08:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Sep 27, 2021, 6:57 PM +0800" prefix="Updated " > Sep 27, 2021 <i class="unloaded">2021-09-27T18:57:55+08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="14696 words">81 min</span></div></div><div class="post-content"><style> h1 { border-bottom: none }</style><p>转载请注明出处：</p><p><a href="https://darkknightzh.github.io/posts/DETR">https://darkknightzh.github.io/posts/DETR</a></p><p>论文：</p><p><a href="https://arxiv.org/abs/2005.12872">https://arxiv.org/abs/2005.12872</a></p><p>官方pytorch代码：</p><p><a href="https://github.com/facebookresearch/detr">https://github.com/facebookresearch/detr</a></p><h1 id="p1简介">P1.简介</h1><p>该文提出基于Transformer的端到端目标检测算法（DEtection TRansformer, DETR），该算法基于以下算法：用于集合预测的二分图最大匹配损失，基于transformer的编码器-解码器结构，并行解码，目标检测算法。</p><p>目前常用的两阶段检测器根据候选框预测坐标，一阶段检测器根据anchor或者网格预测目标，本文则根据输入图像直接预测检测的绝对坐标。</p><p>之前没有经典的深度学习模型直接预测集合。基本的集合预测方式是多标签分类，如1-vs-多，这种方式不适合检测领域，因为检测中元素之间有相近的低层结构（接近的bbox）。大多数检测器使用nms等后处理方法来解决该问题，但是直接集合预测是无需后处理的。该文使用二分匹配损失，但和之前做法不同的是，该文不再使用回归模型，而是将transformers和并行解码结合起来，可以更好的均衡计算代价和坐标预测时全局计算的性能。传统的两阶段检测器根据候选框预测坐标，一阶段检测器根据anchor或者网格预测目标，本文则是根据输入图像直接预测检测的绝对坐标。DETR总体结构如图1所示，训练阶段使用二分匹配来匹配预测框和GT框（真值框，ground truth框）。未匹配到的预测框是”无目标”类别。DETR一次性预测所有目标，并且使用预测目标和GT目标二分匹配的集合损失进行端到端的训练。DETR不使用空间anchors和NMS，简化了检测过程。并且DETR无需额外层，直接使用标准CNN和transformer即可。</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/post/2021-08-21-DETR/1.png" alt="1" /> <em>图1</em></p><h1 id="p2-detr">P2. DETR</h1><p>直接序列预测中有2个主要因素：（1）保证预测框和GT框匹配唯一性的集合预测损失。（2）预测不同目标和目标之间关系的网络结构。</p><h2 id="p21-集合预测损失">P2.1 集合预测损失</h2><p>DERT使用二分图最大匹配对预测框和GT框进行匹配，并做出固定的N个预测，从而得到bbox的损失。N比一张图像中目标数量略大一些。</p><p>令y为目标的GT集合， \(\tilde{y}=\left\{ { { {\tilde{y}}}_{i}} \right\}_{i=1}^{N}\) 为N个预测集合。假定N大于图像中目标的数量，因而可以对y使用 \(\varnothing\) （代表没有目标）填充成大小同样为N的集合。为了找到这两个集合间二分图的最大匹配结果，需要找到一个包含N个元素的序列 \(\sigma \in { {S}_{N}}\) （论文中为</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/post/2021-08-21-DETR/b1.png" alt="b1" /></p><p>，打不出来该字母） ，使得公式1损失最小：</p>\[\hat{\sigma }=\underset{\sigma \in { {S}_{N}}}{\mathop \arg \min }\,\sum\limits_{i}^{N}{ { {L}_{match}}\left( { {y}_{i}},{ { {\hat{y}}}_{\sigma \left( i \right)}} \right)} \tag{1}\]<p>其中 \({ {L}_{match}}\left( { {y}_{i}},{ { {\hat{y}}}_{\sigma \left( i \right)}} \right)\) 为GT值 \({ {y}_{i}}\) 和使用 \(\sigma \left( i \right)\) 进行索引的预测值之间成对的匹配损失。这个最优匹配可以使用匈牙利算法（Hungarian algorithm）高效计算。该匹配损失同时考虑到了类别预测的分类损失和预测框和GT框之间相似性的bbox回归损失。每个GT集合的元素i可以认为是 \({ {y}_{i}}=\left( { {c}_{i}},{ {b}_{i}} \right)\)， 其中 \({ {c}_{i}}\) 为实际目标类别（可以为 \(\varnothing\) ）， \({ {b}_{i}}\in { {\left[ 0,1 \right]}^{4}}\) 为一个定义了GT框中心坐标和归一化宽、高的4维向量。对于使用 \(\sigma \left( i \right)\) 进行索引的预测值，定义 \({ {\hat{p}}_{\sigma \left( i \right)}}\left( { {c}_{i}} \right)\) 为类别 \({ {c}_{i}}\) 的概率， \({ {\hat{b}}_{\sigma \left( i \right)}}\) 为预测框。因而（注意，原论文中未单独标记该公式）：</p>\[{ {L}_{match}}\left( { {y}_{i}},{ { {\hat{y}}}_{\sigma \left( i \right)}} \right)=-{ {1}_{\left\{ { {c}_{i}}\ne \varnothing \right\}}}{ {\hat{p}}_{\sigma \left( i \right)}}\left( { {c}_{i}} \right)+{ {1}_{\left\{ { {c}_{i}}\ne \varnothing \right\}}}{ {L}_{box}}\left( { {b}_{i}},{ { {\hat{b}}}_{\sigma \left( i \right)}} \right) \tag{2}\]<p>此处直接使用概率（未使用log，下面公式3使用了log），因而前后两项度量单位相同，实验结果中性能更好。此处进行匹配的过程和使用anchor来找到GT目标的作用相同。区别是此处需要找到预测框和GT框无重复且1对1的匹配。</p><p>经过上述匹配之后，第二步是计算所有匹配结果的Hungarian损失。该损失和常见的目标检测的损失相同，都是类别预测的负似然对数和下文定义的目标框损失的线性组合（注意，原论文中此处为公式2）：</p>\[{ {L}_{Hungarian}}\left( y,\hat{y} \right)=\sum\limits_{i=1}^{N}{\left[ -\log { { {\hat{p}}}_{\sigma \left( i \right)}}\left( { {c}_{i}} \right)+{ {1}_{\left\{ { {c}_{i}}\ne \varnothing \right\}}}{ {L}_{box}}\left( { {b}_{i}},{ { {\hat{b}}}_{\hat{\sigma }\left( i \right)}} \right) \right]} \tag{3}\]<p>其中 \(\hat{\sigma }\) 为公式1找到的最优匹配结果。实际中，为了平衡正负样本不均衡性，将负样本的log项权重降低到1/10。这种做法和Faster R-CNN训练正负样本候选框的方式相似。</p><p><strong>目标框损失（Bounding box loss）</strong>：匹配损失（公式2）和Hungarian损失（公式3）中的第二项用来对边边界框进行打分。该文直接预测目标框。这样能简化实现代码，但是会有另外的问题。相对误差很小的大目标和小目标在使用如L1损失时，直接预测目标框时损失会相差很大。为了减弱该问题，本文使用L1损失和GIOU损失（generalized IoU loss）的线性组合（注意，原论文中未单独标记该公式）：</p>\[{ {L}_{box}}\left( { {b}_{i}},{ { {\hat{b}}}_{\sigma \left( i \right)}} \right)={ {\lambda }_{iou}}{ {L}_{iou}}\left( { {b}_{i}},{ { {\hat{b}}}_{\sigma \left( i \right)}} \right)+{ {\lambda }_{L1}}{ {\left\| { {b}_{i}}-{ { {\hat{b}}}_{\sigma \left( i \right)}} \right\|}_{1}} \tag{4}\]<p>其中 \({ {\lambda }_{iou}},{ {\lambda }_{L1}}\in \mathbb{R}\) 均为超参。这两个损失通过当前batch中目标的数量进行归一化。</p><h2 id="p22-detr结构">P2.2 DETR结构</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/post/2021-08-21-DETR/2.png" alt="1" /> <em>图2</em></p><p>DETR结构如图2所示，其包括3个主要部分：用于提取特征的CNN骨干网络，编码器-解码器结构的transformer，用于得到最终检测结果的前馈神经网络（feed forward network， FFN）。</p><p><strong>骨干网络</strong>：假定输入图像 \({ {x}_{img}}\in { {\mathbb{R}}^{3\times { {H}_{0}}\times { {W}_{0}}}}\) （输入不同尺寸的图像得到一个batch的输入，使用0填充确保所有图像都和当前batch中最大图像的尺寸 \({ {H}_{0}}\times { {W}_{0}}\) 相同），CNN骨干网络会得到低分辨率的特征图 \(f\in { {\mathbb{R}}^{C\times H\times W}}\) 。其中C=2048， \(H,W=\frac{ { {H}_{0}}}{32},\frac{ { {W}_{0}}}{32}\) 。</p><p><strong>transformer编码器</strong>：首先使用1*1卷积将输入特征通道从C降低到d维，从而得到新的特征 \({ {z}_{0}}\in { {\mathbb{R}}^{d\times H\times W}}\) ，由于编码器需要序列作为输入，因而将输入 \({ {z}_{0}}\) 的空间方向转换成1维，从而得到 \(d \times HW\) 维的输入特征。每个编码器层都使用标准的结构，切包含多头自注意力模块和前行神经网络（FFN）模块。由于transformer结构具有置换不变性，因而将固定位置编码添加到每个注意力层的输入中。补充材料给出网络的详细定义，这与<a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>中的描述相同。</p><p><strong>transformer解码器</strong>：解码器使用transformer标准结构，使用N个d维的多头自注意力和编码器-解码器注意力机制进行变换。该文和原始transformer的区别是，该模型在每个解码器层并行解码N个目标，而原作者<a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>使用自回归模型一次预测一个元素的输出。不熟悉相关概念的读者可参见补充材料。由于解码器也具有置换不变性，N个输入特征必须均不相同，这样才能得到不同的结果。这些输入特征学习的是位置编码，我们称作object queries，和编码器类似，将他们添加到每个注意力层的输入中。N个object queries通过解码器变换到输出特征，而后在通过前向神经网络（FFN，下面介绍）独立解码成目标框的坐标和目标类别，得到N个最终的预测结果。对这些特征使用自注意力和编码器-解码器注意力，模型能够使用目标之间的成对关系，同事能够使用整个图像的信息来预测目标。</p><p><strong>预测的前向神经网络（Prediction feed-forward networks, FFNs）</strong>：最终的预测使用使用ReLU作为激活函数且隐含维度为d的3层感知器，和一个线性投影层。FFN预测目标相对于输入图像的归一化坐标中心、宽、高。线性投影层使用softmax预测目标类别。由于本文预测固定数量N的边界框，通常N远大于图像中实际的目标数量，因而额外的类别 \(\varnothing\) 代表当前预测框中无目标。该类别类似于标准目标检测方法中的“背景”类别。</p><p><strong>辅助解码损失（Auxiliary decoding losses）</strong>：我们发现在训练阶段的解码器中使用辅助损失（<a href="https://arxiv.org/abs/1808.04444">https://arxiv.org/abs/1808.04444</a>）是有帮助的，特别是有利于模型输出每个类别正确的目标数量。因而该文每个解码层之后增加了预测FFNs和Hungarian损失。所有的预测FFNs共享权重。使用额外的共享layer-norm层将不同解码层的输入归一化到FFN层。</p><h1 id="p3代码">P3.代码</h1><h2 id="p31-训练和测试">P3.1 训练和测试</h2><p>位于engine.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">criterion</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">criterion</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">metric_logger</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nc">MetricLogger</span><span class="p">(</span><span class="n">delimiter</span><span class="o">=</span><span class="sh">"</span><span class="s">  </span><span class="sh">"</span><span class="p">)</span>
    <span class="n">metric_logger</span><span class="p">.</span><span class="nf">add_meter</span><span class="p">(</span><span class="sh">'</span><span class="s">lr</span><span class="sh">'</span><span class="p">,</span> <span class="n">utils</span><span class="p">.</span><span class="nc">SmoothedValue</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">{value:.6f}</span><span class="sh">'</span><span class="p">))</span>
    <span class="n">metric_logger</span><span class="p">.</span><span class="nf">add_meter</span><span class="p">(</span><span class="sh">'</span><span class="s">class_error</span><span class="sh">'</span><span class="p">,</span> <span class="n">utils</span><span class="p">.</span><span class="nc">SmoothedValue</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">{value:.2f}</span><span class="sh">'</span><span class="p">))</span>
    <span class="n">header</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Epoch: [{}]</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="n">print_freq</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="k">for</span> <span class="n">samples</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">metric_logger</span><span class="p">.</span><span class="nf">log_every</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">print_freq</span><span class="p">,</span> <span class="n">header</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="p">[{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>  <span class="c1"># 通过网络，得到输出的dict：pred_logits、pred_boxes、aux_outputs
</span>        <span class="n">loss_dict</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">weight_dict</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">.</span><span class="n">weight_dict</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">weight_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="p">.</span><span class="nf">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">weight_dict</span><span class="p">)</span>

        <span class="c1"># reduce losses over all GPUs for logging purposes
</span>        <span class="n">loss_dict_reduced</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nf">reduce_dict</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">)</span>
        <span class="n">loss_dict_reduced_unscaled</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">_unscaled</span><span class="sh">'</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss_dict_reduced</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
        <span class="n">loss_dict_reduced_scaled</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">*</span> <span class="n">weight_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss_dict_reduced</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">weight_dict</span><span class="p">}</span>
        <span class="n">losses_reduced_scaled</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">loss_dict_reduced_scaled</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>

        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">losses_reduced_scaled</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">math</span><span class="p">.</span><span class="nf">isfinite</span><span class="p">(</span><span class="n">loss_value</span><span class="p">):</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Loss is {}, stopping training</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">loss_value</span><span class="p">))</span>
            <span class="nf">print</span><span class="p">(</span><span class="n">loss_dict_reduced</span><span class="p">)</span>
            <span class="n">sys</span><span class="p">.</span><span class="nf">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">losses</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">max_norm</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="n">metric_logger</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss_value</span><span class="p">,</span> <span class="o">**</span><span class="n">loss_dict_reduced_scaled</span><span class="p">,</span> <span class="o">**</span><span class="n">loss_dict_reduced_unscaled</span><span class="p">)</span>
        <span class="n">metric_logger</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">class_error</span><span class="o">=</span><span class="n">loss_dict_reduced</span><span class="p">[</span><span class="sh">'</span><span class="s">class_error</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">metric_logger</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">optimizer</span><span class="p">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">lr</span><span class="sh">"</span><span class="p">])</span>
    <span class="c1"># gather the stats from all processes
</span>    <span class="n">metric_logger</span><span class="p">.</span><span class="nf">synchronize_between_processes</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Averaged stats:</span><span class="sh">"</span><span class="p">,</span> <span class="n">metric_logger</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">meter</span><span class="p">.</span><span class="n">global_avg</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">meter</span> <span class="ow">in</span> <span class="n">metric_logger</span><span class="p">.</span><span class="n">meters</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>

<span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">postprocessors</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">base_ds</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">criterion</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

    <span class="n">metric_logger</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nc">MetricLogger</span><span class="p">(</span><span class="n">delimiter</span><span class="o">=</span><span class="sh">"</span><span class="s">  </span><span class="sh">"</span><span class="p">)</span>
    <span class="n">metric_logger</span><span class="p">.</span><span class="nf">add_meter</span><span class="p">(</span><span class="sh">'</span><span class="s">class_error</span><span class="sh">'</span><span class="p">,</span> <span class="n">utils</span><span class="p">.</span><span class="nc">SmoothedValue</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">{value:.2f}</span><span class="sh">'</span><span class="p">))</span>
    <span class="n">header</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Test:</span><span class="sh">'</span>

    <span class="n">iou_types</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">(</span><span class="sh">'</span><span class="s">segm</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">bbox</span><span class="sh">'</span><span class="p">)</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">postprocessors</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span>
    <span class="n">coco_evaluator</span> <span class="o">=</span> <span class="nc">CocoEvaluator</span><span class="p">(</span><span class="n">base_ds</span><span class="p">,</span> <span class="n">iou_types</span><span class="p">)</span>
    <span class="c1"># coco_evaluator.coco_eval[iou_types[0]].params.iouThrs = [0, 0.1, 0.5, 0.75]
</span>
    <span class="n">panoptic_evaluator</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">panoptic</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">postprocessors</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>   <span class="c1"># coco实例分割
</span>        <span class="n">panoptic_evaluator</span> <span class="o">=</span> <span class="nc">PanopticEvaluator</span><span class="p">(</span><span class="n">data_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">ann_file</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">ann_folder</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sh">"</span><span class="s">panoptic_eval</span><span class="sh">"</span><span class="p">),)</span>

    <span class="k">for</span> <span class="n">samples</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">metric_logger</span><span class="p">.</span><span class="nf">log_every</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">header</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="p">[{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">loss_dict</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">weight_dict</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">.</span><span class="n">weight_dict</span>

        <span class="c1"># reduce losses over all GPUs for logging purposes
</span>        <span class="n">loss_dict_reduced</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nf">reduce_dict</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">)</span>
        <span class="n">loss_dict_reduced_scaled</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">*</span> <span class="n">weight_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss_dict_reduced</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">weight_dict</span><span class="p">}</span>
        <span class="n">loss_dict_reduced_unscaled</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s">_unscaled</span><span class="sh">'</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">loss_dict_reduced</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
        <span class="n">metric_logger</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="nf">sum</span><span class="p">(</span><span class="n">loss_dict_reduced_scaled</span><span class="p">.</span><span class="nf">values</span><span class="p">()),</span> <span class="o">**</span><span class="n">loss_dict_reduced_scaled</span><span class="p">,</span> <span class="o">**</span><span class="n">loss_dict_reduced_unscaled</span><span class="p">)</span>
        <span class="n">metric_logger</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">class_error</span><span class="o">=</span><span class="n">loss_dict_reduced</span><span class="p">[</span><span class="sh">'</span><span class="s">class_error</span><span class="sh">'</span><span class="p">])</span>

        <span class="n">orig_target_sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">t</span><span class="p">[</span><span class="sh">"</span><span class="s">orig_size</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">postprocessors</span><span class="p">[</span><span class="sh">'</span><span class="s">bbox</span><span class="sh">'</span><span class="p">](</span><span class="n">outputs</span><span class="p">,</span> <span class="n">orig_target_sizes</span><span class="p">)</span>   <span class="c1"># 当前batch中每张图像的scores、labels、boxes，均为[N]，总体为list
</span>        <span class="k">if</span> <span class="sh">'</span><span class="s">segm</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">postprocessors</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
            <span class="n">target_sizes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">t</span><span class="p">[</span><span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">postprocessors</span><span class="p">[</span><span class="sh">'</span><span class="s">segm</span><span class="sh">'</span><span class="p">](</span><span class="n">results</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">orig_target_sizes</span><span class="p">,</span> <span class="n">target_sizes</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">{</span><span class="n">target</span><span class="p">[</span><span class="sh">'</span><span class="s">image_id</span><span class="sh">'</span><span class="p">].</span><span class="nf">item</span><span class="p">():</span> <span class="n">output</span> <span class="k">for</span> <span class="n">target</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">results</span><span class="p">)}</span>
        <span class="k">if</span> <span class="n">coco_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">coco_evaluator</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">panoptic_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">res_pano</span> <span class="o">=</span> <span class="n">postprocessors</span><span class="p">[</span><span class="sh">"</span><span class="s">panoptic</span><span class="sh">"</span><span class="p">](</span><span class="n">outputs</span><span class="p">,</span> <span class="n">target_sizes</span><span class="p">,</span> <span class="n">orig_target_sizes</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">targets</span><span class="p">):</span>
                <span class="n">image_id</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">image_id</span><span class="sh">"</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">file_name</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">image_id</span><span class="si">:</span><span class="mi">012</span><span class="n">d</span><span class="si">}</span><span class="s">.png</span><span class="sh">"</span>
                <span class="n">res_pano</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">"</span><span class="s">image_id</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_id</span>
                <span class="n">res_pano</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">"</span><span class="s">file_name</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_name</span>

            <span class="n">panoptic_evaluator</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">res_pano</span><span class="p">)</span>

    <span class="c1"># gather the stats from all processes
</span>    <span class="n">metric_logger</span><span class="p">.</span><span class="nf">synchronize_between_processes</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Averaged stats:</span><span class="sh">"</span><span class="p">,</span> <span class="n">metric_logger</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">coco_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">coco_evaluator</span><span class="p">.</span><span class="nf">synchronize_between_processes</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">panoptic_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">panoptic_evaluator</span><span class="p">.</span><span class="nf">synchronize_between_processes</span><span class="p">()</span>

    <span class="c1"># accumulate predictions from all images
</span>    <span class="k">if</span> <span class="n">coco_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">coco_evaluator</span><span class="p">.</span><span class="nf">accumulate</span><span class="p">()</span>
        <span class="n">coco_evaluator</span><span class="p">.</span><span class="nf">summarize</span><span class="p">()</span>
    <span class="n">panoptic_res</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="n">panoptic_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">panoptic_res</span> <span class="o">=</span> <span class="n">panoptic_evaluator</span><span class="p">.</span><span class="nf">summarize</span><span class="p">()</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">meter</span><span class="p">.</span><span class="n">global_avg</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">meter</span> <span class="ow">in</span> <span class="n">metric_logger</span><span class="p">.</span><span class="n">meters</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
    <span class="k">if</span> <span class="n">coco_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="sh">'</span><span class="s">bbox</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">postprocessors</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
            <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">coco_eval_bbox</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">coco_evaluator</span><span class="p">.</span><span class="n">coco_eval</span><span class="p">[</span><span class="sh">'</span><span class="s">bbox</span><span class="sh">'</span><span class="p">].</span><span class="n">stats</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
        <span class="k">if</span> <span class="sh">'</span><span class="s">segm</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">postprocessors</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
            <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">coco_eval_masks</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">coco_evaluator</span><span class="p">.</span><span class="n">coco_eval</span><span class="p">[</span><span class="sh">'</span><span class="s">segm</span><span class="sh">'</span><span class="p">].</span><span class="n">stats</span><span class="p">.</span><span class="nf">tolist</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">panoptic_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">PQ_all</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">panoptic_res</span><span class="p">[</span><span class="sh">"</span><span class="s">All</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">PQ_th</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">panoptic_res</span><span class="p">[</span><span class="sh">"</span><span class="s">Things</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">PQ_st</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">panoptic_res</span><span class="p">[</span><span class="sh">"</span><span class="s">Stuff</span><span class="sh">"</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">stats</span><span class="p">,</span> <span class="n">coco_evaluator</span>
</pre></table></code></div></div></details><h2 id="p32-创建模型损失后处理信息build_model">P3.2 创建模型，损失，后处理信息build_model</h2><p>位于models/<strong>init</strong>.py，进一步调用build</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">build</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></table></code></div></div></details><h3 id="p321-build">P3.2.1 build</h3><p>位于models/detr.py。</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="c1"># the `num_classes` naming here is somewhat misleading. it indeed corresponds to `max_obj_id + 1`, where max_obj_id is the maximum id for a class in your dataset. For example, COCO has
</span>    <span class="c1"># a max_obj_id of 90, so we pass `num_classes` to be 91. As another example, for a dataset that has a single class with id 1, you should pass `num_classes` to be 2 (max_obj_id + 1).
</span>    <span class="c1"># For more details on this, check the following discussion https://github.com/facebookresearch/detr/issues/108#issuecomment-650269223
</span>    <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">20</span> <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">dataset_file</span> <span class="o">!=</span> <span class="sh">'</span><span class="s">coco</span><span class="sh">'</span> <span class="k">else</span> <span class="mi">91</span>   <span class="c1"># 实际指数据库目标类别数量+1（背景）
</span>    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">dataset_file</span> <span class="o">==</span> <span class="sh">"</span><span class="s">coco_panoptic</span><span class="sh">"</span><span class="p">:</span>   <span class="c1"># coco实例分割
</span>        <span class="c1"># for panoptic, we just add a num_classes that is large enough to hold max_obj_id + 1, but the exact value doesn't really matter
</span>        <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">250</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">backbone</span> <span class="o">=</span> <span class="nf">build_backbone</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># 骨干网络，forward时返回两个list：特征和编码的位置
</span>    
    <span class="n">transformer</span> <span class="o">=</span> <span class="nf">build_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>   <span class="c1"># transformer层，forward时返回dec_layers=6个decoder结果再stack后的结果
</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">DETR</span><span class="p">(</span><span class="n">backbone</span><span class="p">,</span> <span class="n">transformer</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">num_queries</span><span class="p">,</span> <span class="n">aux_loss</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">aux_loss</span><span class="p">,)</span>  <span class="c1"># 最终的DETR网络   # forward时返回dict，包含pred_logits、pred_boxes和aux_outputs
</span>
    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">masks</span><span class="p">:</span>   <span class="c1"># coco实例分割
</span>        <span class="n">model</span> <span class="o">=</span> <span class="nc">DETRsegm</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">freeze_detr</span><span class="o">=</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">frozen_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">))</span>
    <span class="n">matcher</span> <span class="o">=</span> <span class="nf">build_matcher</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>  <span class="c1"># 匹配部分  forward时计算cost matrix，返回匹配的索引 batch_size个 (index_i, index_j)，每个index_i为选择的预测索引，index_j为相应的选择的目标索引
</span>
    <span class="n">weight_dict</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">loss_ce</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">loss_bbox</span><span class="sh">'</span><span class="p">:</span> <span class="n">args</span><span class="p">.</span><span class="n">bbox_loss_coef</span><span class="p">}</span>  <span class="c1"># bbox_loss_coef=5
</span>    <span class="n">weight_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">loss_giou</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">giou_loss_coef</span>   <span class="c1"># 2
</span>    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">masks</span><span class="p">:</span>    <span class="c1"># coco实例分割
</span>        <span class="n">weight_dict</span><span class="p">[</span><span class="sh">"</span><span class="s">loss_mask</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">mask_loss_coef</span>
        <span class="n">weight_dict</span><span class="p">[</span><span class="sh">"</span><span class="s">loss_dice</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">dice_loss_coef</span>
    <span class="c1"># TODO this is a hack
</span>    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">aux_loss</span><span class="p">:</span>
        <span class="n">aux_weight_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">dec_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>  <span class="c1"># 依次遍历dec_layers-1个解码器中间结果
</span>            <span class="n">aux_weight_dict</span><span class="p">.</span><span class="nf">update</span><span class="p">({</span><span class="n">k</span> <span class="o">+</span> <span class="sa">f</span><span class="sh">'</span><span class="s">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">weight_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">()})</span>
        <span class="n">weight_dict</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">aux_weight_dict</span><span class="p">)</span>  <span class="c1"># 中间结果添加到weight_dict中
</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">boxes</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">cardinality</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">masks</span><span class="p">:</span>   <span class="c1"># coco实例分割
</span>        <span class="n">losses</span> <span class="o">+=</span> <span class="p">[</span><span class="sh">"</span><span class="s">masks</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="nc">SetCriterion</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">matcher</span><span class="o">=</span><span class="n">matcher</span><span class="p">,</span> <span class="n">weight_dict</span><span class="o">=</span><span class="n">weight_dict</span><span class="p">,</span> <span class="n">eos_coef</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">eos_coef</span><span class="p">,</span> <span class="n">losses</span><span class="o">=</span><span class="n">losses</span><span class="p">)</span>   <span class="c1"># 计算损失  eos_coef=0.1
</span>    <span class="n">criterion</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">postprocessors</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">bbox</span><span class="sh">'</span><span class="p">:</span> <span class="nc">PostProcess</span><span class="p">()}</span>
    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">masks</span><span class="p">:</span>     <span class="c1"># coco实例分割
</span>        <span class="n">postprocessors</span><span class="p">[</span><span class="sh">'</span><span class="s">segm</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nc">PostProcessSegm</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">dataset_file</span> <span class="o">==</span> <span class="sh">"</span><span class="s">coco_panoptic</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">is_thing_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">90</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">201</span><span class="p">)}</span>
            <span class="n">postprocessors</span><span class="p">[</span><span class="sh">"</span><span class="s">panoptic</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nc">PostProcessPanoptic</span><span class="p">(</span><span class="n">is_thing_map</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">postprocessors</span>   <span class="c1"># 返回模型、损失、后处理
</span></pre></table></code></div></div></details><h3 id="p322-build_backbone">P3.2.2 build_backbone</h3><p>位于models/backbone.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">build_backbone</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">position_embedding</span> <span class="o">=</span> <span class="nf">build_position_encoding</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>   <span class="c1"># 位置编码网络
</span>    <span class="n">train_backbone</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">lr_backbone</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">return_interm_layers</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">masks</span>   <span class="c1"># 实例分割为True，检测为False
</span>    <span class="n">backbone</span> <span class="o">=</span> <span class="nc">Backbone</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">backbone</span><span class="p">,</span> <span class="n">train_backbone</span><span class="p">,</span> <span class="n">return_interm_layers</span><span class="p">,</span> <span class="n">args</span><span class="p">.</span><span class="n">dilation</span><span class="p">)</span>  <span class="c1"># 骨干网络
</span>    <span class="n">model</span> <span class="o">=</span> <span class="nc">Joiner</span><span class="p">(</span><span class="n">backbone</span><span class="p">,</span> <span class="n">position_embedding</span><span class="p">)</span>   <span class="c1"># 合并骨干网络和位置编码网络
</span>    <span class="n">model</span><span class="p">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">backbone</span><span class="p">.</span><span class="n">num_channels</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></table></code></div></div></details><h4 id="p3221-位置编码build_position_encoding">P3.2.2.1 位置编码build_position_encoding</h4><p>位于models/position_encoding.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">PositionEmbeddingSine</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This is a more standard version of the position embedding, very similar to the one used by the Attention is all you need paper, generalized to work on images.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_pos_feats</span> <span class="o">=</span> <span class="n">num_pos_feats</span>   <span class="c1"># 128
</span>        <span class="n">self</span><span class="p">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="n">self</span><span class="p">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>
        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">normalize</span> <span class="ow">is</span> <span class="bp">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sh">"</span><span class="s">normalize should be True if scale is passed</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">scale</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span>
        <span class="n">self</span><span class="p">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>   <span class="c1"># 2 * pi
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">:</span> <span class="n">NestedTensor</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">.</span><span class="n">tensors</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">.</span><span class="n">mask</span>
        <span class="k">assert</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
        <span class="n">not_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">mask</span>    <span class="c1"># 补全的地方是0，原始图像数据地方是1   BHW
</span>        <span class="n">y_embed</span> <span class="o">=</span> <span class="n">not_mask</span><span class="p">.</span><span class="nf">cumsum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>   <span class="c1"># 在指定维度上求累计和  BHW
</span>        <span class="n">x_embed</span> <span class="o">=</span> <span class="n">not_mask</span><span class="p">.</span><span class="nf">cumsum</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize</span><span class="p">:</span>  <span class="c1"># True
</span>            <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-6</span>
            <span class="n">y_embed</span> <span class="o">=</span> <span class="n">y_embed</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_embed</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">scale</span>   <span class="c1"># -1: 为最后一个，也即在cumsum相应维度之和，此处用于归一化到0-2*pi
</span>            <span class="n">x_embed</span> <span class="o">=</span> <span class="n">x_embed</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">scale</span>

        <span class="n">dim_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_pos_feats</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">dim_t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">temperature</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim_t</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">num_pos_feats</span><span class="p">)</span>   <span class="c1"># 来自attention is all you need中的positional encodings。应该是稍微改进了一点 [num_pos_feats]
</span>
        <span class="n">pos_x</span> <span class="o">=</span> <span class="n">x_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>   <span class="c1"># positional encodings   BHW分别除以dim_t[i]，得到BHW(num_pos_feats)
</span>        <span class="n">pos_y</span> <span class="o">=</span> <span class="n">y_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
        <span class="n">pos_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">((</span><span class="n">pos_x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">].</span><span class="nf">sin</span><span class="p">(),</span> <span class="n">pos_x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">].</span><span class="nf">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">).</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>   <span class="c1"># positional encodings，得到sin和cos结果  [B,H,W,num_pos_feats/2,2]转到[B,H,W,num_pos_feats]，num_pos_feats维度为sin，cos，sin，cos...
</span>        <span class="n">pos_y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">((</span><span class="n">pos_y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">].</span><span class="nf">sin</span><span class="p">(),</span> <span class="n">pos_y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">].</span><span class="nf">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">).</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">pos_y</span><span class="p">,</span> <span class="n">pos_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">).</span><span class="nf">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>   <span class="c1"># 结果拼接，并得到BHW(num_pos_feats*2)，而后permute，得到BCHW，其中C=args.hidden_dim=num_pos_feats*2
</span>        <span class="k">return</span> <span class="n">pos</span>

<span class="k">class</span> <span class="nc">PositionEmbeddingLearned</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Absolute pos embedding, learned.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">row_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="p">)</span>   <span class="c1"># A simple lookup table that stores embeddings of a fixed dictionary and size
</span>        <span class="n">self</span><span class="p">.</span><span class="n">col_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">num_pos_feats</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">row_embed</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">col_embed</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">:</span> <span class="n">NestedTensor</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">.</span><span class="n">tensors</span>   <span class="c1"># BCHW
</span>        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [W]
</span>        <span class="n">j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [H]
</span>        <span class="n">x_emb</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">col_embed</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>   <span class="c1"># 通过查找表nn.Embedding，得到输出   [W,num_pos_feats]
</span>        <span class="n">y_emb</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">row_embed</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>   <span class="c1"># [H,num_pos_feats]
</span>        <span class="c1"># torch.cat:[H,W,2*num_pos_feats]  permute:[2*num_pos_feats,H,W]  unsqueeze+repeat:[B,2*num_pos_feats,H,W]，最终和PositionEmbeddingSine中pos形状一样，都是BCHW，C=args.hidden_dim=num_pos_feats*2
</span>        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">x_emb</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_emb</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="mi">1</span><span class="p">),],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">pos</span>

<span class="k">def</span> <span class="nf">build_position_encoding</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">N_steps</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">//</span> <span class="mi">2</span>   <span class="c1"># hidden_dim: Size of the embeddings (dimension of the transformer)   hidden_dim=256
</span>    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">position_embedding</span> <span class="ow">in</span> <span class="p">(</span><span class="sh">'</span><span class="s">v2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sine</span><span class="sh">'</span><span class="p">):</span>   <span class="c1"># 默认是sine
</span>        <span class="c1"># TODO find a better way of exposing other arguments
</span>        <span class="n">position_embedding</span> <span class="o">=</span> <span class="nc">PositionEmbeddingSine</span><span class="p">(</span><span class="n">N_steps</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>   <span class="c1"># 位置编码网络
</span>    <span class="k">elif</span> <span class="n">args</span><span class="p">.</span><span class="n">position_embedding</span> <span class="ow">in</span> <span class="p">(</span><span class="sh">'</span><span class="s">v3</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">learned</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">position_embedding</span> <span class="o">=</span> <span class="nc">PositionEmbeddingLearned</span><span class="p">(</span><span class="n">N_steps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">not supported </span><span class="si">{</span><span class="n">args</span><span class="p">.</span><span class="n">position_embedding</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">position_embedding</span>
</pre></table></code></div></div></details><h4 id="p3222-骨干网络backbone">P3.2.2.2 骨干网络Backbone</h4><p>位于models/backbone.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">FrozenBatchNorm2d</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    BatchNorm2d where the batch statistics and the affine parameters are fixed.

    Copy-paste from torchvision.misc.ops with added eps before rqsrt,
    without which any other models than torchvision.models.resnet[18,34,50,101]
    produce nans.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">FrozenBatchNorm2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">"</span><span class="s">weight</span><span class="sh">"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">"</span><span class="s">bias</span><span class="sh">"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">"</span><span class="s">running_mean</span><span class="sh">"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">"</span><span class="s">running_var</span><span class="sh">"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_load_from_state_dict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">local_metadata</span><span class="p">,</span> <span class="n">strict</span><span class="p">,</span>
                              <span class="n">missing_keys</span><span class="p">,</span> <span class="n">unexpected_keys</span><span class="p">,</span> <span class="n">error_msgs</span><span class="p">):</span>
        <span class="n">num_batches_tracked_key</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="sh">'</span><span class="s">num_batches_tracked</span><span class="sh">'</span>
        <span class="k">if</span> <span class="n">num_batches_tracked_key</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">num_batches_tracked_key</span><span class="p">]</span>

        <span class="nf">super</span><span class="p">(</span><span class="n">FrozenBatchNorm2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">_load_from_state_dict</span><span class="p">(</span>
            <span class="n">state_dict</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">local_metadata</span><span class="p">,</span> <span class="n">strict</span><span class="p">,</span>
            <span class="n">missing_keys</span><span class="p">,</span> <span class="n">unexpected_keys</span><span class="p">,</span> <span class="n">error_msgs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># move reshapes to the beginning
</span>        <span class="c1"># to make it fuser-friendly
</span>        <span class="n">w</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">rv</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">running_var</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">rm</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">running_mean</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-5</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="p">(</span><span class="n">rv</span> <span class="o">+</span> <span class="n">eps</span><span class="p">).</span><span class="nf">rsqrt</span><span class="p">()</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">rm</span> <span class="o">*</span> <span class="n">scale</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">bias</span>

<span class="k">class</span> <span class="nc">BackboneBase</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">backbone</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">train_backbone</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">return_interm_layers</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">backbone</span><span class="p">.</span><span class="nf">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">train_backbone</span> <span class="ow">or</span> <span class="sh">'</span><span class="s">layer2</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">and</span> <span class="sh">'</span><span class="s">layer3</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">and</span> <span class="sh">'</span><span class="s">layer4</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">parameter</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_interm_layers</span><span class="p">:</span>   <span class="c1"># 实例分割
</span>            <span class="n">return_layers</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">layer1</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">0</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">layer2</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">layer3</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">2</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">layer4</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">3</span><span class="sh">"</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>       <span class="c1"># 检测
</span>            <span class="n">return_layers</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">layer4</span><span class="sh">'</span><span class="p">:</span> <span class="sh">"</span><span class="s">0</span><span class="sh">"</span><span class="p">}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">body</span> <span class="o">=</span> <span class="nc">IntermediateLayerGetter</span><span class="p">(</span><span class="n">backbone</span><span class="p">,</span> <span class="n">return_layers</span><span class="o">=</span><span class="n">return_layers</span><span class="p">)</span>   <span class="c1"># 得到backbone到return_layers的层，由于return_interm_layers=False，输出层为"0":v的dict
</span>        <span class="n">self</span><span class="p">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">:</span> <span class="n">NestedTensor</span><span class="p">):</span>   <span class="c1"># 此段不懂
</span>        <span class="c1"># NestedTensor包含tensor和mask。tensor为输入的图像：BCHW，mask为BHW（pad的位置为True，原始图像位置为False，后面使用时会取反：pad位置为False，原始图像位置为True）
</span>        <span class="c1"># tensors:获取整个batch里面最大的w，h，用0 padding补齐（右，下padding）。
</span>        <span class="n">xs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">body</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">.</span><span class="n">tensors</span><span class="p">)</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NestedTensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>   <span class="c1"># xs为dict。由于return_interm_layers=False，输出层为"0":v。此处遍历dict。见init中IntermediateLayerGetter
</span>            <span class="n">m</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">.</span><span class="n">mask</span>   <span class="c1"># BHW，m为输入图像的batch、高、宽
</span>            <span class="k">assert</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">interpolate</span><span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="bp">None</span><span class="p">].</span><span class="nf">float</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># m[None].shape为[1,b,Hi,Wi]。插值到x.shape[-2:]为[Ho,Wo]，此处将输入图像的mask插值到[B,Ho,Wo]，作为输出的mask
</span>            <span class="n">out</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nc">NestedTensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Backbone</span><span class="p">(</span><span class="n">BackboneBase</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">ResNet backbone with frozen BatchNorm.</span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">train_backbone</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">return_interm_layers</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">dilation</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">backbone</span> <span class="o">=</span> <span class="nf">getattr</span><span class="p">(</span><span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">,</span> <span class="n">name</span><span class="p">)(</span><span class="n">replace_stride_with_dilation</span><span class="o">=</span><span class="p">[</span><span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="n">dilation</span><span class="p">],</span> <span class="n">pretrained</span><span class="o">=</span><span class="nf">is_main_process</span><span class="p">(),</span> <span class="n">norm_layer</span><span class="o">=</span><span class="n">FrozenBatchNorm2d</span><span class="p">)</span>  <span class="c1"># 得到pytorch的backbone
</span>        <span class="n">num_channels</span> <span class="o">=</span> <span class="mi">512</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">(</span><span class="sh">'</span><span class="s">resnet18</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">resnet34</span><span class="sh">'</span><span class="p">)</span> <span class="k">else</span> <span class="mi">2048</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">backbone</span><span class="p">,</span> <span class="n">train_backbone</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">return_interm_layers</span><span class="p">)</span>  <span class="c1"># 调用BackboneBase的__init__
</span></pre></table></code></div></div></details><h4 id="p3223-合并骨干网络和位置编码joiner">P3.2.2.3 合并骨干网络和位置编码Joiner</h4><p>位于models/backbone.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Joiner</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">backbone</span><span class="p">,</span> <span class="n">position_embedding</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="n">backbone</span><span class="p">,</span> <span class="n">position_embedding</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">:</span> <span class="n">NestedTensor</span><span class="p">):</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">self</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">tensor_list</span><span class="p">)</span>   <span class="c1"># self[0]为backbone   tensor_list包括mask和tensors   xs为dict，0：NestedTensor
</span>        <span class="n">out</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">NestedTensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>   <span class="c1"># dict的k和v
</span>            <span class="n">out</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>   <span class="c1"># x为NestedTensor
</span>            <span class="n">pos</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">self</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">tensors</span><span class="p">.</span><span class="n">dtype</span><span class="p">))</span>   <span class="c1"># position encoding   self[1]为position_embedding，此处将backbone的结果输入位置编码网络，得到编码后结果：BCHW，C=args.hidden_dim
</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">pos</span>   <span class="c1"># 返回两个list：特征和编码的位置
</span></pre></table></code></div></div></details><h3 id="p323-build_transformer">P3.2.3 build_transformer</h3><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">build_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">nheads</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">dim_feedforward</span><span class="p">,</span>    <span class="c1"># 256, 0.1, 8, 2048
</span>        <span class="n">num_encoder_layers</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">enc_layers</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">dec_layers</span><span class="p">,</span> <span class="n">normalize_before</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">pre_norm</span><span class="p">,</span> <span class="n">return_intermediate_dec</span><span class="o">=</span><span class="bp">True</span><span class="p">,)</span>  <span class="c1"># 6, 6, False, True
</span></pre></table></code></div></div></details><h4 id="p3231-transformer">P3.2.3.1 Transformer</h4><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># 256, 8, 6, 6, 2048, 0.1,
</span>                 <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">normalize_before</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">return_intermediate_dec</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>   <span class="c1"># relu, False, True
</span>        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="nc">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">normalize_before</span><span class="p">)</span>
        <span class="n">encoder_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span> <span class="k">if</span> <span class="n">normalize_before</span> <span class="k">else</span> <span class="bp">None</span>   <span class="c1"># BN对BHW归一化，LN对CHW归一化   encoder_norm=None
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_encoder_layers</span><span class="p">,</span> <span class="n">encoder_norm</span><span class="p">)</span>

        <span class="n">decoder_layer</span> <span class="o">=</span> <span class="nc">TransformerDecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">normalize_before</span><span class="p">)</span>
        <span class="n">decoder_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="p">,</span> <span class="n">decoder_norm</span><span class="p">,</span> <span class="n">return_intermediate</span><span class="o">=</span><span class="n">return_intermediate_dec</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">_reset_parameters</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">nhead</span> <span class="o">=</span> <span class="n">nhead</span>

    <span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="nf">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">xavier_uniform_</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">query_embed</span><span class="p">,</span> <span class="n">pos_embed</span><span class="p">):</span> 
        <span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">src</span><span class="p">.</span><span class="n">shape</span>   
        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># BCHW转到BC(HW)再转到(HW)BC  # flatten NxCxHxW to HWxNxC
</span>        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="c1"># BCHW转到BC(HW)再转到(HW)BC
</span>        <span class="n">query_embed</span> <span class="o">=</span> <span class="n">query_embed</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># NBC
</span>        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># B(HW)
</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">query_embed</span><span class="p">)</span>
        <span class="n">memory</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">pos_embed</span><span class="p">)</span>   <span class="c1"># (HW)BC
</span>        <span class="n">hs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_key_padding_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">pos_embed</span><span class="p">,</span> <span class="n">query_pos</span><span class="o">=</span><span class="n">query_embed</span><span class="p">)</span>  <span class="c1"># 训练时return_intermediate_dec=True，因而(num_decoder_layers)NBC
</span>        <span class="k">return</span> <span class="n">hs</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">memory</span><span class="p">.</span><span class="nf">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>  <span class="c1"># decoder结果：(num_decoder_layers)BNC，encoder结果：BCHW
</span></pre></table></code></div></div></details><h4 id="p3232-transformerencoder">P3.2.3.2 TransformerEncoder</h4><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="nf">_get_clones</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>   <span class="c1"># 将输入网络复制num_layers=6遍，forward时串行输出（前一个的输出是当前的输入）
</span>        <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">src</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>  <span class="c1"># 依次得到6个encoder_layer的输出
</span>            <span class="n">output</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">src_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding_mask</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">)</span>   <span class="c1"># 串行输出
</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>  <span class="c1"># None
</span>            <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</pre></table></code></div></div></details><h4 id="p3233-transformerencoderlayer">P3.2.3.3 TransformerEncoderLayer</h4><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">TransformerEncoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">normalize_before</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>  <span class="c1"># 多头注意力   nhead=8
</span>        <span class="c1"># Implementation of Feedforward model
</span>        <span class="n">self</span><span class="p">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim_feedforward</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="nf">_get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>  <span class="c1"># relu
</span>        <span class="n">self</span><span class="p">.</span><span class="n">normalize_before</span> <span class="o">=</span> <span class="n">normalize_before</span>   <span class="c1"># False
</span>
    <span class="k">def</span> <span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">pos</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">tensor</span> <span class="o">+</span> <span class="n">pos</span>

    <span class="k">def</span> <span class="nf">forward_post</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="c1"># forward_post和forward_pre区别是LayerNorm位置不同（pre是先LayerNorm在其他操作，post是先其他操作，再LayerNorm）
</span>        <span class="c1"># src → src(+pos) → MultiheadAttention → Dropout → + → LayerNorm → linear1+relu+Dropout+linear2 → Dropout → + → LayerNorm → out
</span>        <span class="c1">#    ↘ -----------------------------------------↗              ↘ --------------------------------------↗
</span>        <span class="n">q</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>  <span class="c1"># pos不为None：src+pos   pos为None：src
</span>        <span class="n">src2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">self_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">src</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">src_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout1</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm1</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="n">src2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear2</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">activation</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">linear1</span><span class="p">(</span><span class="n">src</span><span class="p">))))</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout2</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm2</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">src</span>

    <span class="k">def</span> <span class="nf">forward_pre</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="c1"># forward_post和forward_pre区别是LayerNorm位置不同（pre是先LayerNorm在其他操作，post是先其他操作，再LayerNorm）
</span>        <span class="c1"># src → LayerNorm → src(+pos) → MultiheadAttention → Dropout → + → LayerNorm → linear1+relu+Dropout+linear2 → Dropout → + → out
</span>        <span class="c1">#    ↘ -----------------------------------------------------↗  ↘ --------------------------------------------------↗
</span>        <span class="n">src2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm1</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">src2</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>   <span class="c1"># pos不为None：src2+pos   pos为None：src2
</span>        <span class="n">src2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">self_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">src2</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">src_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout1</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
        <span class="n">src2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm2</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="n">src2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear2</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">activation</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">linear1</span><span class="p">(</span><span class="n">src2</span><span class="p">))))</span>
        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout2</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">src</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize_before</span><span class="p">:</span>   <span class="c1"># False
</span>            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward_pre</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward_post</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>  <span class="c1"># return此处
</span></pre></table></code></div></div></details><h4 id="p3234-transformerdecoder">P3.2.3.4 TransformerDecoder</h4><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">return_intermediate</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="nf">_get_clones</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>    <span class="c1"># 将输入网络复制num_layers=6遍，forward时串行输出（前一个的输出是当前的输入）
</span>        <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="n">self</span><span class="p">.</span><span class="n">return_intermediate</span> <span class="o">=</span> <span class="n">return_intermediate</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                <span class="n">memory_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">tgt</span>

        <span class="n">intermediate</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory_mask</span><span class="o">=</span><span class="n">memory_mask</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding_mask</span><span class="p">,</span>
                           <span class="n">memory_key_padding_mask</span><span class="o">=</span><span class="n">memory_key_padding_mask</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">,</span> <span class="n">query_pos</span><span class="o">=</span><span class="n">query_pos</span><span class="p">)</span>     <span class="c1"># 串行输出
</span>            <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">return_intermediate</span><span class="p">:</span>  <span class="c1"># True
</span>                <span class="n">intermediate</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>  <span class="c1"># 每次保存中间结果
</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>  <span class="c1">#  LayerNorm 此处执行
</span>            <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">return_intermediate</span><span class="p">:</span>
                <span class="n">intermediate</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>   <span class="c1"># 弹出最后一个结果
</span>                <span class="n">intermediate</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>   <span class="c1"># 保存最后norm后的结果
</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">return_intermediate</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">intermediate</span><span class="p">)</span>   <span class="c1"># 返回中间保存的结果
</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 返回最终的结果
</span></pre></table></code></div></div></details><h4 id="p3235-transformerdecoderlayer">P3.2.3.5 TransformerDecoderLayer</h4><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">TransformerDecoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">normalize_before</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">multihead_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="c1"># Implementation of Feedforward model
</span>        <span class="n">self</span><span class="p">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim_feedforward</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="nf">_get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">normalize_before</span> <span class="o">=</span> <span class="n">normalize_before</span>   <span class="c1"># False
</span>
    <span class="k">def</span> <span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">pos</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">tensor</span> <span class="o">+</span> <span class="n">pos</span>

    <span class="k">def</span> <span class="nf">forward_post</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                     <span class="n">memory_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="c1"># forward_post和forward_pre区别是LayerNorm位置不同（pre是先LayerNorm在其他操作，post是先其他操作，再LayerNorm）
</span>        <span class="c1">#                                                                        memory(+pos) ↘
</span>        <span class="c1"># tgt → tgt(+query_pos) → MultiheadAttention → Dropout → + → LayerNorm → +(query_pos) → MultiheadAttention → Dropout → + → LayerNorm → linear1+relu+Dropout+linear2 → Dropout → + → LayerNorm → out
</span>        <span class="c1">#    ↘ -----------------------------------------------↗              ↘ -------------------------------------------↗              ↘ ---------------------------------------↗
</span>        <span class="n">q</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">)</span>   <span class="c1"># query_pos不为None：tgt+query_pos   pos为None：tgt
</span>        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">self_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">tgt</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout1</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">multihead_attn</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">pos</span><span class="p">),</span> 
                                   <span class="n">value</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">memory_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">memory_key_padding_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout2</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm2</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear2</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">activation</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">linear1</span><span class="p">(</span><span class="n">tgt</span><span class="p">))))</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout3</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm3</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tgt</span>

    <span class="k">def</span> <span class="nf">forward_pre</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                    <span class="n">memory_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="c1"># forward_post和forward_pre区别是LayerNorm位置不同（pre是先LayerNorm在其他操作，post是先其他操作，再LayerNorm）
</span>        <span class="c1">#                                                                                memory(+pos) ↘
</span>        <span class="c1"># tgt → LayerNorm → (+query_pos) → MultiheadAttention → Dropout → + → LayerNorm → +(query_pos) → MultiheadAttention → Dropout → + → LayerNorm → linear1+relu+Dropout+linear2 → Dropout → + → out
</span>        <span class="c1">#    ↘ --------------------------------------------------------↗  ↘ -------------------------------------------------------↗   ↘ -------------------------------------------------↗
</span>        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tgt2</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">)</span>   <span class="c1"># query_pos不为None：tgt2+query_pos   pos为None：tgt2
</span>        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">self_attn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">tgt2</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout1</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm2</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">multihead_attn</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tgt2</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">pos</span><span class="p">),</span>
                                   <span class="n">value</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">memory_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">memory_key_padding_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout2</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm3</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
        <span class="n">tgt2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear2</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">activation</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">linear1</span><span class="p">(</span><span class="n">tgt2</span><span class="p">))))</span>
        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout3</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tgt</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> 
                <span class="n">memory_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize_before</span><span class="p">:</span>  <span class="c1"># False
</span>            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward_pre</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="p">,</span> <span class="n">memory_key_padding_mask</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward_post</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">,</span> <span class="n">memory_mask</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="p">,</span> <span class="n">memory_key_padding_mask</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">)</span>  <span class="c1"># 返回此处结果
</span></pre></table></code></div></div></details><h4 id="p3236-_get_activation_fn">P3.2.3.6 _get_activation_fn</h4><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">_get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Return an activation function given a string</span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span>
    <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="sh">"</span><span class="s">gelu</span><span class="sh">"</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">gelu</span>
    <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="sh">"</span><span class="s">glu</span><span class="sh">"</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">glu</span>
    <span class="k">raise</span> <span class="nc">RuntimeError</span><span class="p">(</span><span class="sa">F</span><span class="sh">"</span><span class="s">activation should be relu/gelu, not </span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>
</pre></table></code></div></div></details><h4 id="p3237-_get_clones">P3.2.3.7 _get_clones</h4><p>位于models/transformer.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">_get_clones</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">)])</span>
</pre></table></code></div></div></details><h3 id="p324-detr">P3.2.4 DETR</h3><p>位于models/detr.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">DETR</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s"> This is the DETR module that performs object detection </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">backbone</span><span class="p">,</span> <span class="n">transformer</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">,</span> <span class="n">aux_loss</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Initializes the model.
        Parameters:
            backbone: torch module of the backbone to be used. See backbone.py
            transformer: torch module of the transformer architecture. See transformer.py
            num_classes: number of object classes   目标数量
            num_queries: number of object queries, ie detection slot. This is the maximal number of objects DETR can detect in a single image. For COCO, we recommend 100 queries.
            aux_loss: True if auxiliary decoding losses (loss at each decoder layer) are to be used.
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_queries</span> <span class="o">=</span> <span class="n">num_queries</span>   <span class="c1"># 100
</span>        <span class="n">self</span><span class="p">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">transformer</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">.</span><span class="n">d_model</span>   <span class="c1"># 256
</span>        <span class="n">self</span><span class="p">.</span><span class="n">class_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>   <span class="c1"># 3个fc，外加2个ReLU，最终输出特征维度为4
</span>        <span class="n">self</span><span class="p">.</span><span class="n">query_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">num_queries</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">backbone</span><span class="p">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">backbone</span>
        <span class="n">self</span><span class="p">.</span><span class="n">aux_loss</span> <span class="o">=</span> <span class="n">aux_loss</span>   <span class="c1"># 默认应该是True
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">NestedTensor</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> The forward expects a NestedTensor, which consists of:       NestedTensor包含tensor和mask。tensor为BCHW，mask为BHW（pad的位置为1）
               - samples.tensor: batched images, of shape [batch_size x 3 x H x W]
               - samples.mask: a binary mask of shape [batch_size x H x W], containing 1 on padded pixels

            It returns a dict with the following elements:
               - </span><span class="sh">"</span><span class="s">pred_logits</span><span class="sh">"</span><span class="s">: the classification logits (including no-object) for all queries. Shape= [batch_size x num_queries x (num_classes + 1)]
               - </span><span class="sh">"</span><span class="s">pred_boxes</span><span class="sh">"</span><span class="s">: The normalized boxes coordinates for all queries, represented as (center_x, center_y, height, width). These values are normalized in [0, 1],
                               relative to the size of each individual image (disregarding possible padding). See PostProcess for information on how to retrieve the unnormalized bounding box.
               - </span><span class="sh">"</span><span class="s">aux_outputs</span><span class="sh">"</span><span class="s">: Optional, only returned when auxilary losses are activated. It is a list of dictionnaries containing the two above keys for each decoder layer.
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)):</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="nf">nested_tensor_from_tensor_list</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>   <span class="c1"># 将当前batch中不同宽高的图像转成相同宽高（贴到最大图像左上角），并返回NestedTensor类型的数据
</span>        <span class="n">features</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">backbone</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>   <span class="c1"># 图像通过骨干网络，得到特征：NestedTensor的list，和位置编码：list
</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">decompose</span><span class="p">()</span>  <span class="c1"># 得到最后一个输出的图像和mask
</span>        <span class="k">assert</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
        <span class="n">hs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transformer</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">input_proj</span><span class="p">(</span><span class="n">src</span><span class="p">),</span> <span class="n">mask</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">query_embed</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">pos</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 通过transformer层的encoder和decoder，[0]得到decoder后的结果：(num_decoder_layers)BNC
</span>
        <span class="n">outputs_class</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">class_embed</span><span class="p">(</span><span class="n">hs</span><span class="p">)</span>   <span class="c1"># decoder后结果进行分类
</span>        <span class="n">outputs_coord</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">bbox_embed</span><span class="p">(</span><span class="n">hs</span><span class="p">).</span><span class="nf">sigmoid</span><span class="p">()</span>  <span class="c1"># decoder后结果拟合bbox
</span>        <span class="n">out</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">pred_logits</span><span class="sh">'</span><span class="p">:</span> <span class="n">outputs_class</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">pred_boxes</span><span class="sh">'</span><span class="p">:</span> <span class="n">outputs_coord</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]}</span>  <span class="c1"># 返回最终的结果 (num_decoder_layers)BNC   (num_decoder_layers)BN4
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">aux_loss</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="sh">'</span><span class="s">aux_outputs</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_set_aux_loss</span><span class="p">(</span><span class="n">outputs_class</span><span class="p">,</span> <span class="n">outputs_coord</span><span class="p">)</span>   <span class="c1"># 增加decoder中间层的结果
</span>        <span class="k">return</span> <span class="n">out</span>  <span class="c1"># 返回dict，包含pred_logits、pred_boxes和aux_outputs
</span>
    <span class="nd">@torch.jit.unused</span>
    <span class="k">def</span> <span class="nf">_set_aux_loss</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs_class</span><span class="p">,</span> <span class="n">outputs_coord</span><span class="p">):</span>
        <span class="c1"># this is a workaround to make torchscript happy, as torchscript
</span>        <span class="c1"># doesn't support dictionary with non-homogeneous values, such as a dict having both a Tensor and a list.
</span>        <span class="k">return</span> <span class="p">[{</span><span class="sh">'</span><span class="s">pred_logits</span><span class="sh">'</span><span class="p">:</span> <span class="n">a</span><span class="p">,</span> <span class="sh">'</span><span class="s">pred_boxes</span><span class="sh">'</span><span class="p">:</span> <span class="n">b</span><span class="p">}</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">outputs_class</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs_coord</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])]</span>
</pre></table></code></div></div></details><h3 id="p325-前向神经网络ffn">P3.2.5 前向神经网络FFN</h3><p>位于models/detr.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1"># FFN网络，实际为num_layers个fc，外加num_layers-1个ReLU
</span>    <span class="sh">"""</span><span class="s"> Very simple multi-layer perceptron (also called FFN)</span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="n">h</span> <span class="o">=</span> <span class="p">[</span><span class="n">hidden_dim</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">([</span><span class="n">input_dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">h</span> <span class="o">+</span> <span class="p">[</span><span class="n">output_dim</span><span class="p">]))</span>  <span class="c1"># 多个fc层
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 依次通过每个fc+ReLU，最后一个fc无ReLU
</span>        <span class="k">return</span> <span class="n">x</span>
</pre></table></code></div></div></details><h3 id="p326-build_matcher">P3.2.6 build_matcher</h3><p>位于models/matcher.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">HungarianMatcher</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">This class computes an assignment between the targets and the predictions of the network

    For efficiency reasons, the targets don</span><span class="sh">'</span><span class="s">t include the no_object. Because of this, in general, there are more predictions than targets. In this case, we do a 1-to-1 matching of the best predictions,
    while the others are un-matched (and thus treated as non-objects).

    分配目标和网络的预测结果
    为了更高效，目标不包括“no_object”这个类别。因而预测数量比目标数量要多，因此进行1对1匹配，来得到最好的匹配结果，未匹配上的认为是“no_object”
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">cost_class</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cost_bbox</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cost_giou</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Creates the matcher

        Params:
            cost_class: This is the relative weight of the classification error in the matching cost    分类错误权重 1
            cost_bbox: This is the relative weight of the L1 error of the bounding box coordinates in the matching cost  预测目标框权重  5
            cost_giou: This is the relative weight of the giou loss of the bounding box in the matching cost   预测目标和实际目标的giou损失的权重  2
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cost_class</span> <span class="o">=</span> <span class="n">cost_class</span>   <span class="c1"># 1
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cost_bbox</span> <span class="o">=</span> <span class="n">cost_bbox</span>     <span class="c1"># 5
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cost_giou</span> <span class="o">=</span> <span class="n">cost_giou</span>     <span class="c1"># 2
</span>        <span class="k">assert</span> <span class="n">cost_class</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">cost_bbox</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">cost_giou</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">all costs cant be 0</span><span class="sh">"</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Performs the matching

        Params:
            outputs: This is a dict that contains at least these entries:   网络输出，至少包含pred_logits（BNC）和pred_boxes（BN4）   C为分类数，N为num_queries
                 </span><span class="sh">"</span><span class="s">pred_logits</span><span class="sh">"</span><span class="s">: Tensor of dim [batch_size, num_queries, num_classes] with the classification logits
                 </span><span class="sh">"</span><span class="s">pred_boxes</span><span class="sh">"</span><span class="s">: Tensor of dim [batch_size, num_queries, 4] with the predicted box coordinates

            targets: This is a list of targets (len(targets) = batch_size), where each target is a dict containing:   gt结果，包含labels（num_target_boxes）和boxes（num_target_boxes*4）
                 </span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="s">: Tensor of dim [num_target_boxes] (where num_target_boxes is the number of ground-truth objects in the target) containing the class labels
                 </span><span class="sh">"</span><span class="s">boxes</span><span class="sh">"</span><span class="s">: Tensor of dim [num_target_boxes, 4] containing the target box coordinates

        Returns:
            A list of size batch_size, containing tuples of (index_i, index_j) where:      batch_size个 (index_i, index_j)，每个index_i为选择的预测索引，index_j为相应的选择的目标索引
                - index_i is the indices of the selected predictions (in order)
                - index_j is the indices of the corresponding selected targets (in order)
            For each batch element, it holds:                                               对于每个(index_i, index_j)，len(index_i) = len(index_j) = min(num_queries, num_target_boxes)
                len(index_i) = len(index_j) = min(num_queries, num_target_boxes)
        </span><span class="sh">"""</span>
        <span class="n">bs</span><span class="p">,</span> <span class="n">num_queries</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">pred_logits</span><span class="sh">"</span><span class="p">].</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        
        <span class="c1">#  将结果铺平，用于计算cost matrices。 # We flatten to compute the cost matrices in a batch 
</span>        <span class="n">out_prob</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">pred_logits</span><span class="sh">"</span><span class="p">].</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 得到预测的分类概率  [batch_size*num_queries, num_classes]
</span>        <span class="n">out_bbox</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">pred_boxes</span><span class="sh">"</span><span class="p">].</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 得到预测的bbox  [batch_size*num_queries, 4]
</span>
        <span class="n">tgt_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">])</span>  <span class="c1"># cat gt的label，为batch个dict的list，tgt_ids将所有的labels拼接  [k]   Also concat the target labels and boxes
</span>        <span class="n">tgt_bbox</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">boxes</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">])</span>  <span class="c1"># cat gt的bbox，batch中每个gt有多个box，k为总共目标个数 [k,4]
</span>
        <span class="c1"># Compute the classification cost. Contrary to the loss, we don't use the NLL, but approximate it in 1 - proba[target class]. The 1 is a constant that doesn't change the matching, it can be ommitted.
</span>        <span class="n">cost_class</span> <span class="o">=</span> <span class="o">-</span><span class="n">out_prob</span><span class="p">[:,</span> <span class="n">tgt_ids</span><span class="p">]</span>   <span class="c1"># 得到实际目标的预测概率   此处计算分类损失时，不使用NLL loss，而是近似使用1-proba[target class]。由于1不影响匹配，因而可以忽略 [batch_size*num_queries, k]
</span>
        <span class="n">cost_bbox</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cdist</span><span class="p">(</span><span class="n">out_bbox</span><span class="p">,</span> <span class="n">tgt_bbox</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># 计算out_bbox的每个box和tgt_bbox的每个box的L1距离  [batch_size*num_queries, k]  # Compute the L1 cost between boxes
</span>        <span class="c1"># 计算预测框和gt框的-giou（非GIoU loss=1-GIoU） [batch_size*num_queries, k]
</span>        <span class="n">cost_giou</span> <span class="o">=</span> <span class="o">-</span><span class="nf">generalized_box_iou</span><span class="p">(</span><span class="nf">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">out_bbox</span><span class="p">),</span> <span class="nf">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">tgt_bbox</span><span class="p">))</span>    <span class="c1"># Compute the giou cost betwen boxes
</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">cost_bbox</span> <span class="o">*</span> <span class="n">cost_bbox</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">cost_class</span> <span class="o">*</span> <span class="n">cost_class</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">cost_giou</span> <span class="o">*</span> <span class="n">cost_giou</span>    <span class="c1"># Final cost matrix  [batch_size*num_queries, k]  此处将batch中多个图像的目标混在一起了，下面需要分别得到每个图像上相关目标
</span>        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">cpu</span><span class="p">()</span>  <span class="c1"># [batch_size, num_queries, k]
</span>
        <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nf">len</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">boxes</span><span class="sh">"</span><span class="p">])</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">]</span>   <span class="c1"># batch中每个图像的gt目标个数
</span>        <span class="c1"># 依次对当前batch每张图像上cost matrix使用匈牙利算法计算分配的索引  torch.split将tensor根据sizes进行拆分：[batch_size, num_queries, ki]  linear_sum_assignment返回row_ind, col_ind : array
</span>        <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="nf">linear_sum_assignment</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">C</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))]</span>  <span class="c1"># i为batch中图像索引，c[i]表示batch中第i个图像：[num_queries, ki]，上面将batch中多个图像目标混在一起，此处拆分，得到每个图像分配的索引
</span>        <span class="k">return</span> <span class="p">[(</span><span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>   <span class="c1"># 返回匹配的索引
</span>
<span class="k">def</span> <span class="nf">build_matcher</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>   <span class="c1"># 计算cost matrix，返回匹配的索引 batch_size个 (index_i, index_j)，每个index_i为选择的预测索引，index_j为相应的选择的目标索引
</span>    <span class="k">return</span> <span class="nc">HungarianMatcher</span><span class="p">(</span><span class="n">cost_class</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">set_cost_class</span><span class="p">,</span> <span class="n">cost_bbox</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">set_cost_bbox</span><span class="p">,</span> <span class="n">cost_giou</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">set_cost_giou</span><span class="p">)</span>  <span class="c1"># 1, 5, 2
</span></pre></table></code></div></div></details><h3 id="p327-计算损失setcriterion">P3.2.7 计算损失SetCriterion</h3><p>位于models/detr.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">SetCriterion</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s"> This class computes the loss for DETR.  计算DETR损失：1. 计算gt和预测的二分匹配 2. 监督每组匹配的gt和预测结果（监督类别和box）
    The process happens in two steps:
        1) we compute hungarian assignment between ground truth boxes and the outputs of the model
        2) we supervise each pair of matched ground-truth / prediction (supervise class and box)
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">matcher</span><span class="p">,</span> <span class="n">weight_dict</span><span class="p">,</span> <span class="n">eos_coef</span><span class="p">,</span> <span class="n">losses</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Create the criterion.
        Parameters:
            num_classes: number of object categories, omitting the special no-object category 
            matcher: module able to compute a matching between targets and proposals  
            weight_dict: dict containing as key the names of the losses and as values their relative weight.  
            eos_coef: relative classification weight applied to the no-object category    
            losses: list of all the losses to be applied. See get_loss for list of available losses.  
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>                         <span class="c1"># 类别数量（忽略背景）
</span>        <span class="n">self</span><span class="p">.</span><span class="n">matcher</span> <span class="o">=</span> <span class="n">matcher</span>                                 <span class="c1"># 匹配函数，forward时得到匹配结果
</span>        <span class="n">self</span><span class="p">.</span><span class="n">weight_dict</span> <span class="o">=</span> <span class="n">weight_dict</span>                         <span class="c1"># 字典，key为损失名字，val为相应损失的权重
</span>        <span class="n">self</span><span class="p">.</span><span class="n">eos_coef</span> <span class="o">=</span> <span class="n">eos_coef</span>                               <span class="c1"># 负样本（背景）权重  0.1
</span>        <span class="n">self</span><span class="p">.</span><span class="n">losses</span> <span class="o">=</span> <span class="n">losses</span>                                   <span class="c1"># 所有需要计算的loss的list
</span>        <span class="n">empty_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">empty_weight</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">eos_coef</span>                       <span class="c1"># 每个类别的权重。最后负样本权重设置为0.1
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">empty_weight</span><span class="sh">'</span><span class="p">,</span> <span class="n">empty_weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loss_labels</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>  <span class="c1"># 分类损失
</span>        <span class="sh">"""</span><span class="s">Classification loss (NLL)   
        targets dicts must contain the key </span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="s"> containing a tensor of dim [nb_target_boxes]</span><span class="sh">"""</span>
        <span class="k">assert</span> <span class="sh">'</span><span class="s">pred_logits</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">outputs</span>
        <span class="n">src_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_logits</span><span class="sh">'</span><span class="p">]</span>    <span class="c1"># 特征  BNC   C为分类类别
</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_src_permutation_idx</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>   <span class="c1"># batch索引，匹配的索引
</span>        <span class="n">target_classes_o</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">t</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">][</span><span class="n">J</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">J</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">)])</span>   <span class="c1"># 目标类别  targets和indices都是list，J为当前batch的label中gt的索引，t["labels"][J]得到gt的实际label，最终得到当前batch中所有的gt的label
</span>        <span class="n">target_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">full</span><span class="p">(</span><span class="n">src_logits</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src_logits</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># 得到和src_logits形状相同的矩阵，默认填充值均为背景   [B,N]
</span>        <span class="n">target_classes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">target_classes_o</span>   <span class="c1"># 目标中相应位置设置为相应类，如 target_classes_o=1,1,1,64,1,64,170...类别为什么不是1，
</span>
        <span class="n">loss_ce</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">src_logits</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">target_classes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">empty_weight</span><span class="p">)</span>  <span class="c1"># 计算交叉熵，BCN和BN
</span>        <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">loss_ce</span><span class="sh">'</span><span class="p">:</span> <span class="n">loss_ce</span><span class="p">}</span>

        <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
            <span class="c1"># TODO this should probably be a separate loss, not hacked in this one here
</span>            <span class="n">losses</span><span class="p">[</span><span class="sh">'</span><span class="s">class_error</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">src_logits</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">target_classes_o</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>   <span class="c1"># 错误率
</span>        <span class="k">return</span> <span class="n">losses</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">loss_cardinality</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">):</span>   <span class="c1"># 预测bbox损失，只是为了显示使用，并非真的计算损失，不反传梯度
</span>        <span class="sh">"""</span><span class="s"> Compute the cardinality error, ie the absolute error in the number of predicted non-empty boxes   预测的非空box的绝对错误数量
        This is not really a loss, it is intended for logging purposes only. It doesn</span><span class="sh">'</span><span class="s">t propagate gradients</span><span class="sh">"""</span>
        <span class="n">pred_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_logits</span><span class="sh">'</span><span class="p">]</span>      <span class="c1"># 特征  BNC   C为分类类别
</span>        <span class="n">device</span> <span class="o">=</span> <span class="n">pred_logits</span><span class="p">.</span><span class="n">device</span>
        <span class="n">tgt_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">([</span><span class="nf">len</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">])</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># 当前batch中每个图像的gt目标数量，[B]
</span>        <span class="c1"># Count the number of predictions that are NOT "no-object" (which is the last class)
</span>        <span class="n">card_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_logits</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="n">pred_logits</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># card_pred：[B]  pred_logits.argmax(-1).shape：BN  pred_logits.shape[-1]-1为背景的类别。!=表示预测的类别不是背景，.sum(1)表示batch中每个图像上预测目标不是背景的数量 
</span>        <span class="n">card_err</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">l1_loss</span><span class="p">(</span><span class="n">card_pred</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">tgt_lengths</span><span class="p">.</span><span class="nf">float</span><span class="p">())</span>   <span class="c1"># 计算损失   这个只是为了显示用，实际上却是没什么意义。card_pred里面元素应该一直是100，就是N。tgt_lengths里面元素依当前图像目标而定，因而该损失没什么实际意义。
</span>        <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">cardinality_error</span><span class="sh">'</span><span class="p">:</span> <span class="n">card_err</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">losses</span>

    <span class="k">def</span> <span class="nf">loss_boxes</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">):</span>   <span class="c1"># 计算预测box的损失，包括L1拟合的损失和GIoU损失
</span>        <span class="sh">"""</span><span class="s">Compute the losses related to the bounding boxes, the L1 regression loss and the GIoU loss
           targets dicts must contain the key </span><span class="sh">"</span><span class="s">boxes</span><span class="sh">"</span><span class="s"> containing a tensor of dim [nb_target_boxes, 4]
           The target boxes are expected in format (center_x, center_y, w, h), normalized by the image size.
        </span><span class="sh">"""</span>
        <span class="k">assert</span> <span class="sh">'</span><span class="s">pred_boxes</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">outputs</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_src_permutation_idx</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>     <span class="c1"># batch索引，匹配的索引
</span>        <span class="n">src_boxes</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_boxes</span><span class="sh">'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>   <span class="c1"># 得到匹配的预测框
</span>        <span class="n">target_boxes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">t</span><span class="p">[</span><span class="sh">'</span><span class="s">boxes</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>   <span class="c1"># 得到匹配的gt框  targets和indices都是list，i为当前batch的label中gt的索引，t["boxes"][i]得到gt的实际box，最终得到当前batch中所有的gt的box
</span>
        <span class="n">loss_bbox</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">l1_loss</span><span class="p">(</span><span class="n">src_boxes</span><span class="p">,</span> <span class="n">target_boxes</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">)</span>   <span class="c1"># 预测框和目标框的L1损失
</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">losses</span><span class="p">[</span><span class="sh">'</span><span class="s">loss_bbox</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_bbox</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">num_boxes</span>   <span class="c1"># 归一化L1损失
</span>        
        <span class="c1"># generalized_box_iou：计算GIoU，输入均为[x0, y0, x1, y1]。返回为len(boxes1)*len(boxes2)的矩阵
</span>        <span class="n">loss_giou</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">box_ops</span><span class="p">.</span><span class="nf">generalized_box_iou</span><span class="p">(</span><span class="n">box_ops</span><span class="p">.</span><span class="nf">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">src_boxes</span><span class="p">),</span> <span class="n">box_ops</span><span class="p">.</span><span class="nf">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">target_boxes</span><span class="p">)))</span>  <span class="c1"># 对角上为GIoU，1-GIoU为GIoU loss
</span>        <span class="n">losses</span><span class="p">[</span><span class="sh">'</span><span class="s">loss_giou</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_giou</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">num_boxes</span>   <span class="c1"># 归一化的GIoU loss
</span>        <span class="k">return</span> <span class="n">losses</span>

    <span class="k">def</span> <span class="nf">loss_masks</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Compute the losses related to the masks: the focal loss and the dice loss.
           targets dicts must contain the key </span><span class="sh">"</span><span class="s">masks</span><span class="sh">"</span><span class="s"> containing a tensor of dim [nb_target_boxes, h, w]
        </span><span class="sh">"""</span>
        <span class="k">assert</span> <span class="sh">"</span><span class="s">pred_masks</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">outputs</span>

        <span class="n">src_idx</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_src_permutation_idx</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">tgt_idx</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_tgt_permutation_idx</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">src_masks</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">pred_masks</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">src_masks</span> <span class="o">=</span> <span class="n">src_masks</span><span class="p">[</span><span class="n">src_idx</span><span class="p">]</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="sh">"</span><span class="s">masks</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">]</span>
        <span class="c1"># TODO use valid to mask invalid areas due to padding in loss
</span>        <span class="n">target_masks</span><span class="p">,</span> <span class="n">valid</span> <span class="o">=</span> <span class="nf">nested_tensor_from_tensor_list</span><span class="p">(</span><span class="n">masks</span><span class="p">).</span><span class="nf">decompose</span><span class="p">()</span>
        <span class="n">target_masks</span> <span class="o">=</span> <span class="n">target_masks</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">src_masks</span><span class="p">)</span>
        <span class="n">target_masks</span> <span class="o">=</span> <span class="n">target_masks</span><span class="p">[</span><span class="n">tgt_idx</span><span class="p">]</span>

        <span class="c1"># upsample predictions to the target size
</span>        <span class="n">src_masks</span> <span class="o">=</span> <span class="nf">interpolate</span><span class="p">(</span><span class="n">src_masks</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">target_masks</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span>
                                <span class="n">mode</span><span class="o">=</span><span class="sh">"</span><span class="s">bilinear</span><span class="sh">"</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">src_masks</span> <span class="o">=</span> <span class="n">src_masks</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">target_masks</span> <span class="o">=</span> <span class="n">target_masks</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_masks</span> <span class="o">=</span> <span class="n">target_masks</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">src_masks</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">loss_mask</span><span class="sh">"</span><span class="p">:</span> <span class="nf">sigmoid_focal_loss</span><span class="p">(</span><span class="n">src_masks</span><span class="p">,</span> <span class="n">target_masks</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">),</span>
            <span class="sh">"</span><span class="s">loss_dice</span><span class="sh">"</span><span class="p">:</span> <span class="nf">dice_loss</span><span class="p">(</span><span class="n">src_masks</span><span class="p">,</span> <span class="n">target_masks</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">losses</span>

    <span class="k">def</span> <span class="nf">_get_src_permutation_idx</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="c1"># permute predictions following indices
</span>        <span class="n">batch_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">full_like</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">)])</span>   <span class="c1"># full_like(src, i)生成一个和src大小一样的tensor，填充值均为i，此处得到batch索引
</span>        <span class="n">src_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">src</span> <span class="nf">for </span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>  <span class="c1"># 得到匹配的索引
</span>        <span class="k">return</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">src_idx</span>   <span class="c1"># 返回batch索引，匹配的索引
</span>
    <span class="k">def</span> <span class="nf">_get_tgt_permutation_idx</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="c1"># permute targets following indices
</span>        <span class="n">batch_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">full_like</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">)])</span>
        <span class="n">tgt_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">tgt</span> <span class="nf">for </span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">tgt_idx</span>

    <span class="k">def</span> <span class="nf">get_loss</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">loss_map</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">loss_labels</span><span class="p">,</span> <span class="sh">'</span><span class="s">cardinality</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">loss_cardinality</span><span class="p">,</span> <span class="sh">'</span><span class="s">boxes</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">loss_boxes</span><span class="p">,</span> <span class="sh">'</span><span class="s">masks</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">loss_masks</span><span class="p">}</span>   <span class="c1"># 代码中使用的所有loss
</span>        <span class="k">assert</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">loss_map</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">do you really want to compute </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s"> loss?</span><span class="sh">'</span>
        <span class="k">return</span> <span class="n">loss_map</span><span class="p">[</span><span class="n">loss</span><span class="p">](</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>   <span class="c1"># 返回相应的loss结果
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> This performs the loss computation.
        Parameters:
             outputs: dict of tensors, see the output specification of the model for the format      # dict，包含pred_logits、pred_boxes和aux_outputs
             targets: list of dicts, such that len(targets) == batch_size. The expected keys in each dict depends on the losses applied, see each loss</span><span class="sh">'</span><span class="s"> doc
        </span><span class="sh">"""</span>
        <span class="n">outputs_without_aux</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="sh">'</span><span class="s">aux_outputs</span><span class="sh">'</span><span class="p">}</span>   <span class="c1"># pred_logits、pred_boxes
</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">matcher</span><span class="p">(</span><span class="n">outputs_without_aux</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>    <span class="c1"># matcher的forward，得到匹配的索引：batch_size个 (index_i, index_j)   Retrieve the matching between the outputs of the last layer and the targets
</span>
        <span class="n">num_boxes</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">])</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">)</span>  <span class="c1"># 得到当前batch中总共目标数量，右侧为生成器表达式，通过sum求和  # Compute the average number of target boxes accross all nodes, for normalization purposes
</span>        <span class="n">num_boxes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">([</span><span class="n">num_boxes</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="nf">next</span><span class="p">(</span><span class="nf">iter</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="nf">values</span><span class="p">())).</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">is_dist_avail_and_initialized</span><span class="p">():</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">distributed</span><span class="p">.</span><span class="nf">all_reduce</span><span class="p">(</span><span class="n">num_boxes</span><span class="p">)</span>
        <span class="n">num_boxes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">clamp</span><span class="p">(</span><span class="n">num_boxes</span> <span class="o">/</span> <span class="nf">get_world_size</span><span class="p">(),</span> <span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>   <span class="c1"># 计算每个gpu上box数量    get_world_size()返回分布式使用的gpu数量，单个gpu返回1
</span>
        <span class="c1"># Compute all the requested losses
</span>        <span class="n">losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">:</span>   <span class="c1"># 依次遍历每个需要计算的loss
</span>            <span class="n">losses</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">get_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">))</span>   <span class="c1"># 依次计算每个loss
</span>
        <span class="k">if</span> <span class="sh">'</span><span class="s">aux_outputs</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>  <span class="c1"># 如果有额外的输出，则计算额外的损失  # In case of auxiliary losses, we repeat this process with the output of each intermediate layer.  
</span>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">aux_outputs</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">aux_outputs</span><span class="sh">'</span><span class="p">]):</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">matcher</span><span class="p">(</span><span class="n">aux_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>    <span class="c1"># 中间层结果和gt进行匹配
</span>                <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">loss</span> <span class="o">==</span> <span class="sh">'</span><span class="s">masks</span><span class="sh">'</span><span class="p">:</span>
                        <span class="c1"># Intermediate masks losses are too costly to compute, we ignore them.
</span>                        <span class="k">continue</span>
                    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">if</span> <span class="n">loss</span> <span class="o">==</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">:</span>
                        <span class="c1"># Logging is enabled only for the last layer
</span>                        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">log</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>
                    <span class="n">l_dict</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">get_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">aux_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">num_boxes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>   <span class="c1"># 计算中间层损失
</span>                    <span class="n">l_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span> <span class="o">+</span> <span class="sa">f</span><span class="sh">'</span><span class="s">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">l_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
                    <span class="n">losses</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">l_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">losses</span>  <span class="c1"># 返回总的损失的dict
</span></pre></table></code></div></div></details><h3 id="p328-accuracy">P3.2.8 accuracy</h3><p>位于util/misc.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)):</span>
    <span class="sh">"""</span><span class="s">Computes the precision@k for the specified values of k</span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">target</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([],</span> <span class="n">device</span><span class="o">=</span><span class="n">output</span><span class="p">.</span><span class="n">device</span><span class="p">)]</span>
    <span class="n">maxk</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">topk</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">topk</span><span class="p">(</span><span class="n">maxk</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="nf">t</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="nf">eq</span><span class="p">(</span><span class="n">target</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">expand_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">topk</span><span class="p">:</span>
        <span class="n">correct_k</span> <span class="o">=</span> <span class="n">correct</span><span class="p">[:</span><span class="n">k</span><span class="p">].</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">float</span><span class="p">().</span><span class="nf">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">res</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">correct_k</span><span class="p">.</span><span class="nf">mul_</span><span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></table></code></div></div></details><h3 id="p329-giou-generalized_box_iou">P3.2.9 GIOU generalized_box_iou</h3><p>位于util/box_ops.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre><td class="rouge-code"><pre><span class="c1"># modified from torchvision to also return the union
</span><span class="k">def</span> <span class="nf">box_iou</span><span class="p">(</span><span class="n">boxes1</span><span class="p">,</span> <span class="n">boxes2</span><span class="p">):</span>
    <span class="n">area1</span> <span class="o">=</span> <span class="nf">box_area</span><span class="p">(</span><span class="n">boxes1</span><span class="p">)</span>   <span class="c1"># 得到每个框的面积   [N]  N=len(boxes1)
</span>    <span class="n">area2</span> <span class="o">=</span> <span class="nf">box_area</span><span class="p">(</span><span class="n">boxes2</span><span class="p">)</span>   <span class="c1"># 得到每个框的面积   [M]  M=len(boxes2)
</span>
    <span class="n">lt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">boxes1</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">boxes2</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># [N,M,2]   左上角坐标
</span>    <span class="n">rb</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">boxes1</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">:],</span> <span class="n">boxes2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>  <span class="c1"># [N,M,2]   右下角坐标
</span>
    <span class="n">wh</span> <span class="o">=</span> <span class="p">(</span><span class="n">rb</span> <span class="o">-</span> <span class="n">lt</span><span class="p">).</span><span class="nf">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [N,M,2]     重叠区域宽高
</span>    <span class="n">inter</span> <span class="o">=</span> <span class="n">wh</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">wh</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># [N,M]   两个box交集的面积
</span>
    <span class="n">union</span> <span class="o">=</span> <span class="n">area1</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">area2</span> <span class="o">-</span> <span class="n">inter</span>   <span class="c1"># 两个box并集的面积  [N,M]
</span>
    <span class="n">iou</span> <span class="o">=</span> <span class="n">inter</span> <span class="o">/</span> <span class="n">union</span>   <span class="c1"># IoU  [N,M]
</span>    <span class="k">return</span> <span class="n">iou</span><span class="p">,</span> <span class="n">union</span>   <span class="c1"># 返回IoU和并集的面积，大小均为[len(boxes1), len(boxes2]
</span>
<span class="k">def</span> <span class="nf">generalized_box_iou</span><span class="p">(</span><span class="n">boxes1</span><span class="p">,</span> <span class="n">boxes2</span><span class="p">):</span>   <span class="c1"># 计算GIoU，输入均为[x0, y0, x1, y1]。返回为len(boxes1)*len(boxes2)的矩阵
</span>    <span class="sh">"""</span><span class="s">
    Generalized IoU from https://giou.stanford.edu/

    The boxes should be in [x0, y0, x1, y1] format

    Returns a [N, M] pairwise matrix, where N = len(boxes1) and M = len(boxes2)
    </span><span class="sh">"""</span>
    <span class="c1"># degenerate boxes gives inf / nan results
</span>    <span class="c1"># so do an early check
</span>    <span class="nf">assert </span><span class="p">(</span><span class="n">boxes1</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">&gt;=</span> <span class="n">boxes1</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]).</span><span class="nf">all</span><span class="p">()</span>   <span class="c1"># 终点坐标&gt;起点坐标
</span>    <span class="nf">assert </span><span class="p">(</span><span class="n">boxes2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">&gt;=</span> <span class="n">boxes2</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]).</span><span class="nf">all</span><span class="p">()</span>
    <span class="n">iou</span><span class="p">,</span> <span class="n">union</span> <span class="o">=</span> <span class="nf">box_iou</span><span class="p">(</span><span class="n">boxes1</span><span class="p">,</span> <span class="n">boxes2</span><span class="p">)</span>  <span class="c1"># IoU和并集的面积，大小均为[len(boxes1), len(boxes2]
</span>
    <span class="n">lt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">boxes1</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">boxes2</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>   <span class="c1"># 预测和gt相应框的外围框的左上角坐标
</span>    <span class="n">rb</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">boxes1</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">:],</span> <span class="n">boxes2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>   <span class="c1"># 预测和gt相应框的外围框的右下角坐标
</span>
    <span class="n">wh</span> <span class="o">=</span> <span class="p">(</span><span class="n">rb</span> <span class="o">-</span> <span class="n">lt</span><span class="p">).</span><span class="nf">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [N,M,2]   # 预测和gt相应框的外围框的宽高
</span>    <span class="n">area</span> <span class="o">=</span> <span class="n">wh</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">wh</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>   <span class="c1"># 预测和gt相应框的外围框的面积
</span>
    <span class="k">return</span> <span class="n">iou</span> <span class="o">-</span> <span class="p">(</span><span class="n">area</span> <span class="o">-</span> <span class="n">union</span><span class="p">)</span> <span class="o">/</span> <span class="n">area</span>   <span class="c1"># GIoU  [len(boxes1), len(boxes2]
</span></pre></table></code></div></div></details><h3 id="p3210-后处理postprocess">P3.2.10 后处理PostProcess</h3><p>位于models/detr.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">PostProcess</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1"># 将模型输出转换成coco api支持的格式
</span>    <span class="sh">"""</span><span class="s"> This module converts the model</span><span class="sh">'</span><span class="s">s output into the format expected by the coco api</span><span class="sh">"""</span>
    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">target_sizes</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s"> Perform the computation
        Parameters:
            outputs: raw outputs of the model   模型输出
            target_sizes: tensor of dimension [batch_size x 2] containing the size of each images of the batch   当前batch中每个图像的宽高，测试时必须为扰动之前的图像宽高；显示时，为扰动之后、pad之前的图像大小
                          For evaluation, this must be the original image size (before any data augmentation). For visualization, this should be the image size after data augment, but before padding
        </span><span class="sh">"""</span>
        <span class="n">out_logits</span><span class="p">,</span> <span class="n">out_bbox</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_logits</span><span class="sh">'</span><span class="p">],</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_boxes</span><span class="sh">'</span><span class="p">]</span>    <span class="c1"># BNC   BN4   C为分类的类别数
</span>
        <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">out_logits</span><span class="p">)</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">target_sizes</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">target_sizes</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

        <span class="n">prob</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">out_logits</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># 预测概率  # BNC
</span>        <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">prob</span><span class="p">[...,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># 预测分值、预测标签（预测最后一类时，为背景）  # 均为[B,N]
</span>
        <span class="n">boxes</span> <span class="o">=</span> <span class="n">box_ops</span><span class="p">.</span><span class="nf">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">out_bbox</span><span class="p">)</span>   <span class="c1"># 转成xyxy格式   convert to [x0, y0, x1, y1] format   BN4
</span>        <span class="n">img_h</span><span class="p">,</span> <span class="n">img_w</span> <span class="o">=</span> <span class="n">target_sizes</span><span class="p">.</span><span class="nf">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># and from relative [0, 1] to absolute [0, height] coordinates   均为[B]
</span>        <span class="n">scale_fct</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">img_w</span><span class="p">,</span> <span class="n">img_h</span><span class="p">,</span> <span class="n">img_w</span><span class="p">,</span> <span class="n">img_h</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span> <span class="o">*</span> <span class="n">scale_fct</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>   <span class="c1"># 从相对坐标转成绝对坐标     BN4
</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[{</span><span class="sh">'</span><span class="s">scores</span><span class="sh">'</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">:</span> <span class="n">l</span><span class="p">,</span> <span class="sh">'</span><span class="s">boxes</span><span class="sh">'</span><span class="p">:</span> <span class="n">b</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">boxes</span><span class="p">)]</span>  <span class="c1"># coco api支持的格式   得到当前batch中每张图像的scores、labels、boxes，均为[N]，总体为list
</span>
        <span class="k">return</span> <span class="n">results</span>  <span class="c1"># 当前batch中每张图像的scores、labels、boxes，均为[N]，总体为list
</span></pre></table></code></div></div></details><h2 id="p33-训练时coco数据库cocodetection">P3.3 训练时COCO数据库CocoDetection</h2><p>位于datasets/coco.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">CocoDetection</span><span class="p">(</span><span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">CocoDetection</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">img_folder</span><span class="p">,</span> <span class="n">ann_file</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">return_masks</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">CocoDetection</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">img_folder</span><span class="p">,</span> <span class="n">ann_file</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">_transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="n">self</span><span class="p">.</span><span class="n">prepare</span> <span class="o">=</span> <span class="nc">ConvertCocoPolysToMask</span><span class="p">(</span><span class="n">return_masks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="nf">super</span><span class="p">(</span><span class="n">CocoDetection</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__getitem__</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>  <span class="c1"># 调用系统的CocoDetection得到图像和标注信息
</span>        <span class="n">image_id</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">image_id</span><span class="sh">'</span><span class="p">:</span> <span class="n">image_id</span><span class="p">,</span> <span class="sh">'</span><span class="s">annotations</span><span class="sh">'</span><span class="p">:</span> <span class="n">target</span><span class="p">}</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>   <span class="c1"># 调用ConvertCocoPolysToMask进行处理
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_transforms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>   <span class="c1"># 对图像进行扰动
</span>        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span>

<span class="k">def</span> <span class="nf">convert_coco_poly_to_mask</span><span class="p">(</span><span class="n">segmentations</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">):</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">polygons</span> <span class="ow">in</span> <span class="n">segmentations</span><span class="p">:</span>
        <span class="n">rles</span> <span class="o">=</span> <span class="n">coco_mask</span><span class="p">.</span><span class="nf">frPyObjects</span><span class="p">(</span><span class="n">polygons</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">coco_mask</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">rles</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">mask</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nf">any</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">masks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">masks</span><span class="p">:</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">masks</span>

<span class="k">class</span> <span class="nc">ConvertCocoPolysToMask</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">return_masks</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">return_masks</span> <span class="o">=</span> <span class="n">return_masks</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">size</span>

        <span class="n">image_id</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">image_id</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">image_id</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">image_id</span><span class="p">])</span>

        <span class="n">anno</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">annotations</span><span class="sh">"</span><span class="p">]</span>

        <span class="n">anno</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">anno</span> <span class="k">if</span> <span class="sh">'</span><span class="s">iscrowd</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">obj</span> <span class="ow">or</span> <span class="n">obj</span><span class="p">[</span><span class="sh">'</span><span class="s">iscrowd</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">boxes</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span><span class="p">[</span><span class="sh">"</span><span class="s">bbox</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">]</span>
        <span class="c1"># guard against no boxes via resizing
</span>        <span class="n">boxes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">+=</span> <span class="n">boxes</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">].</span><span class="nf">clamp_</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
        <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">].</span><span class="nf">clamp_</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>

        <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span><span class="p">[</span><span class="sh">"</span><span class="s">category_id</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">]</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">return_masks</span><span class="p">:</span>
            <span class="n">segmentations</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span><span class="p">[</span><span class="sh">"</span><span class="s">segmentation</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">]</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="nf">convert_coco_poly_to_mask</span><span class="p">(</span><span class="n">segmentations</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

        <span class="n">keypoints</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">anno</span> <span class="ow">and</span> <span class="sh">"</span><span class="s">keypoints</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">keypoints</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span><span class="p">[</span><span class="sh">"</span><span class="s">keypoints</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">]</span>
            <span class="n">keypoints</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">(</span><span class="n">keypoints</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">num_keypoints</span> <span class="o">=</span> <span class="n">keypoints</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">num_keypoints</span><span class="p">:</span>
                <span class="n">keypoints</span> <span class="o">=</span> <span class="n">keypoints</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">num_keypoints</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="n">keep</span> <span class="o">=</span> <span class="p">(</span><span class="n">boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">return_masks</span><span class="p">:</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">keypoints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">keypoints</span> <span class="o">=</span> <span class="n">keypoints</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>

        <span class="n">target</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">boxes</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">boxes</span>
        <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">classes</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">return_masks</span><span class="p">:</span>
            <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">masks</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">masks</span>
        <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">image_id</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_id</span>
        <span class="k">if</span> <span class="n">keypoints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">keypoints</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">keypoints</span>

        <span class="c1"># for conversion to coco api
</span>        <span class="n">area</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">obj</span><span class="p">[</span><span class="sh">"</span><span class="s">area</span><span class="sh">"</span><span class="p">]</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">])</span>
        <span class="n">iscrowd</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">obj</span><span class="p">[</span><span class="sh">"</span><span class="s">iscrowd</span><span class="sh">"</span><span class="p">]</span> <span class="k">if</span> <span class="sh">"</span><span class="s">iscrowd</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">obj</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">])</span>
        <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">area</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">area</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
        <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">iscrowd</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">iscrowd</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>

        <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">orig_size</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">([</span><span class="nf">int</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="nf">int</span><span class="p">(</span><span class="n">w</span><span class="p">)])</span>
        <span class="n">target</span><span class="p">[</span><span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">as_tensor</span><span class="p">([</span><span class="nf">int</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="nf">int</span><span class="p">(</span><span class="n">w</span><span class="p">)])</span>

        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">target</span>

<span class="k">def</span> <span class="nf">make_coco_transforms</span><span class="p">(</span><span class="n">image_set</span><span class="p">):</span>   <span class="c1"># 数据扰动
</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>   <span class="c1"># 标准化
</span>        <span class="n">T</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
        <span class="n">T</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])])</span>

    <span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="mi">480</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">544</span><span class="p">,</span> <span class="mi">576</span><span class="p">,</span> <span class="mi">608</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">672</span><span class="p">,</span> <span class="mi">704</span><span class="p">,</span> <span class="mi">736</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="mi">800</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">image_set</span> <span class="o">==</span> <span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">T</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
            <span class="n">T</span><span class="p">.</span><span class="nc">RandomHorizontalFlip</span><span class="p">(),</span>   <span class="c1"># 水平镜像
</span>            <span class="n">T</span><span class="p">.</span><span class="nc">RandomSelect</span><span class="p">(</span>    <span class="c1"># 随机选择下面的
</span>                <span class="n">T</span><span class="p">.</span><span class="nc">RandomResize</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>      <span class="c1"># 随机缩放
</span>                <span class="n">T</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
                    <span class="n">T</span><span class="p">.</span><span class="nc">RandomResize</span><span class="p">([</span><span class="mi">400</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">]),</span>        <span class="c1"># 随机缩放
</span>                    <span class="n">T</span><span class="p">.</span><span class="nc">RandomSizeCrop</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">600</span><span class="p">),</span>             <span class="c1"># 随机裁剪
</span>                    <span class="n">T</span><span class="p">.</span><span class="nc">RandomResize</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>  <span class="c1"># 随机缩放
</span>                <span class="p">])</span>
            <span class="p">),</span>
            <span class="n">normalize</span><span class="p">,</span>                                      <span class="c1"># 标准化
</span>        <span class="p">])</span>

    <span class="k">if</span> <span class="n">image_set</span> <span class="o">==</span> <span class="sh">'</span><span class="s">val</span><span class="sh">'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">T</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
            <span class="n">T</span><span class="p">.</span><span class="nc">RandomResize</span><span class="p">([</span><span class="mi">800</span><span class="p">],</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>   <span class="c1"># 随机缩放
</span>            <span class="n">normalize</span><span class="p">,</span>
        <span class="p">])</span>

    <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">unknown </span><span class="si">{</span><span class="n">image_set</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="n">image_set</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
    <span class="n">root</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">coco_path</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">root</span><span class="p">.</span><span class="nf">exists</span><span class="p">(),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">provided COCO path </span><span class="si">{</span><span class="n">root</span><span class="si">}</span><span class="s"> does not exist</span><span class="sh">'</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="sh">'</span><span class="s">instances</span><span class="sh">'</span>
    <span class="n">PATHS</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span> <span class="o">/</span> <span class="sh">"</span><span class="s">train2017</span><span class="sh">"</span><span class="p">,</span> <span class="n">root</span> <span class="o">/</span> <span class="sh">"</span><span class="s">annotations</span><span class="sh">"</span> <span class="o">/</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s">_train2017.json</span><span class="sh">'</span><span class="p">),</span>
             <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span> <span class="o">/</span> <span class="sh">"</span><span class="s">val2017</span><span class="sh">"</span><span class="p">,</span> <span class="n">root</span> <span class="o">/</span> <span class="sh">"</span><span class="s">annotations</span><span class="sh">"</span> <span class="o">/</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s">_val2017.json</span><span class="sh">'</span><span class="p">),}</span>

    <span class="n">img_folder</span><span class="p">,</span> <span class="n">ann_file</span> <span class="o">=</span> <span class="n">PATHS</span><span class="p">[</span><span class="n">image_set</span><span class="p">]</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">CocoDetection</span><span class="p">(</span><span class="n">img_folder</span><span class="p">,</span> <span class="n">ann_file</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="nf">make_coco_transforms</span><span class="p">(</span><span class="n">image_set</span><span class="p">),</span> <span class="n">return_masks</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">masks</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>
</pre></table></code></div></div></details><h2 id="p34-测试时coco数据库cocoevaluator">P3.4 测试时COCO数据库CocoEvaluator</h2><p>位于datasets/coco_eval.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">CocoEvaluator</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">coco_gt</span><span class="p">,</span> <span class="n">iou_types</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">iou_types</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
        <span class="n">coco_gt</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">coco_gt</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">coco_gt</span> <span class="o">=</span> <span class="n">coco_gt</span>

        <span class="n">self</span><span class="p">.</span><span class="n">iou_types</span> <span class="o">=</span> <span class="n">iou_types</span>
        <span class="n">self</span><span class="p">.</span><span class="n">coco_eval</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">iou_type</span> <span class="ow">in</span> <span class="n">iou_types</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">coco_eval</span><span class="p">[</span><span class="n">iou_type</span><span class="p">]</span> <span class="o">=</span> <span class="nc">COCOeval</span><span class="p">(</span><span class="n">coco_gt</span><span class="p">,</span> <span class="n">iouType</span><span class="o">=</span><span class="n">iou_type</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">img_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">eval_imgs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">iou_types</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="n">img_ids</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">predictions</span><span class="p">.</span><span class="nf">keys</span><span class="p">())))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">img_ids</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">img_ids</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">iou_type</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">iou_types</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">prepare</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">iou_type</span><span class="p">)</span>   <span class="c1"># predictions：当前batch中每张图像的scores、labels、boxes，均为[N]，总体为list
</span>
            <span class="c1"># suppress pycocotools prints
</span>            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">devnull</span><span class="p">,</span> <span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">devnull</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">contextlib</span><span class="p">.</span><span class="nf">redirect_stdout</span><span class="p">(</span><span class="n">devnull</span><span class="p">):</span>
                    <span class="n">coco_dt</span> <span class="o">=</span> <span class="n">COCO</span><span class="p">.</span><span class="nf">loadRes</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">coco_gt</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span> <span class="k">if</span> <span class="n">results</span> <span class="k">else</span> <span class="nc">COCO</span><span class="p">()</span>
            <span class="n">coco_eval</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">coco_eval</span><span class="p">[</span><span class="n">iou_type</span><span class="p">]</span>

            <span class="n">coco_eval</span><span class="p">.</span><span class="n">cocoDt</span> <span class="o">=</span> <span class="n">coco_dt</span>
            <span class="n">coco_eval</span><span class="p">.</span><span class="n">params</span><span class="p">.</span><span class="n">imgIds</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">img_ids</span><span class="p">)</span>
            <span class="n">img_ids</span><span class="p">,</span> <span class="n">eval_imgs</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">coco_eval</span><span class="p">)</span>

            <span class="n">self</span><span class="p">.</span><span class="n">eval_imgs</span><span class="p">[</span><span class="n">iou_type</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">eval_imgs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">synchronize_between_processes</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">iou_type</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">iou_types</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">eval_imgs</span><span class="p">[</span><span class="n">iou_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">eval_imgs</span><span class="p">[</span><span class="n">iou_type</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
            <span class="nf">create_common_coco_eval</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">coco_eval</span><span class="p">[</span><span class="n">iou_type</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">img_ids</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">eval_imgs</span><span class="p">[</span><span class="n">iou_type</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">accumulate</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">coco_eval</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">coco_eval</span><span class="p">.</span><span class="nf">values</span><span class="p">():</span>
            <span class="n">coco_eval</span><span class="p">.</span><span class="nf">accumulate</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">summarize</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">iou_type</span><span class="p">,</span> <span class="n">coco_eval</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">coco_eval</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">IoU metric: {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">iou_type</span><span class="p">))</span>
            <span class="n">coco_eval</span><span class="p">.</span><span class="nf">summarize</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">prepare</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">iou_type</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">iou_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">bbox</span><span class="sh">"</span><span class="p">:</span>   <span class="c1"># 检测为此处
</span>            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">prepare_for_coco_detection</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">iou_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">segm</span><span class="sh">"</span><span class="p">:</span>   <span class="c1"># 实例分割为此处
</span>            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">prepare_for_coco_segmentation</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">iou_type</span> <span class="o">==</span> <span class="sh">"</span><span class="s">keypoints</span><span class="sh">"</span><span class="p">:</span>   <span class="c1"># 姿态估计为此处
</span>            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">prepare_for_coco_keypoint</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sh">"</span><span class="s">Unknown iou type {}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">iou_type</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">prepare_for_coco_detection</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="n">coco_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">original_id</span><span class="p">,</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">boxes</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">boxes</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="nf">convert_to_xywh</span><span class="p">(</span><span class="n">boxes</span><span class="p">).</span><span class="nf">tolist</span><span class="p">()</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">scores</span><span class="sh">"</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>

            <span class="n">coco_results</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="sh">"</span><span class="s">image_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">original_id</span><span class="p">,</span>
                        <span class="sh">"</span><span class="s">category_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
                        <span class="sh">"</span><span class="s">bbox</span><span class="sh">"</span><span class="p">:</span> <span class="n">box</span><span class="p">,</span>
                        <span class="sh">"</span><span class="s">score</span><span class="sh">"</span><span class="p">:</span> <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
                    <span class="p">}</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">box</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">boxes</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">coco_results</span>

    <span class="k">def</span> <span class="nf">prepare_for_coco_segmentation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="n">coco_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">original_id</span><span class="p">,</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">scores</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">scores</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">masks</span><span class="sh">"</span><span class="p">]</span>

            <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span> <span class="o">&gt;</span> <span class="mf">0.5</span>

            <span class="n">scores</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">scores</span><span class="sh">"</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>

            <span class="n">rles</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">mask_util</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">mask</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">"</span><span class="s">F</span><span class="sh">"</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">masks</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">rle</span> <span class="ow">in</span> <span class="n">rles</span><span class="p">:</span>
                <span class="n">rle</span><span class="p">[</span><span class="sh">"</span><span class="s">counts</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">rle</span><span class="p">[</span><span class="sh">"</span><span class="s">counts</span><span class="sh">"</span><span class="p">].</span><span class="nf">decode</span><span class="p">(</span><span class="sh">"</span><span class="s">utf-8</span><span class="sh">"</span><span class="p">)</span>

            <span class="n">coco_results</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="sh">"</span><span class="s">image_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">original_id</span><span class="p">,</span>
                        <span class="sh">"</span><span class="s">category_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
                        <span class="sh">"</span><span class="s">segmentation</span><span class="sh">"</span><span class="p">:</span> <span class="n">rle</span><span class="p">,</span>
                        <span class="sh">"</span><span class="s">score</span><span class="sh">"</span><span class="p">:</span> <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
                    <span class="p">}</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">rle</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">rles</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">coco_results</span>

    <span class="k">def</span> <span class="nf">prepare_for_coco_keypoint</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="n">coco_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">original_id</span><span class="p">,</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">boxes</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">boxes</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="nf">convert_to_xywh</span><span class="p">(</span><span class="n">boxes</span><span class="p">).</span><span class="nf">tolist</span><span class="p">()</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">scores</span><span class="sh">"</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
            <span class="n">keypoints</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="sh">"</span><span class="s">keypoints</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">keypoints</span> <span class="o">=</span> <span class="n">keypoints</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">tolist</span><span class="p">()</span>

            <span class="n">coco_results</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="sh">"</span><span class="s">image_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">original_id</span><span class="p">,</span>
                        <span class="sh">"</span><span class="s">category_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
                        <span class="sh">'</span><span class="s">keypoints</span><span class="sh">'</span><span class="p">:</span> <span class="n">keypoint</span><span class="p">,</span>
                        <span class="sh">"</span><span class="s">score</span><span class="sh">"</span><span class="p">:</span> <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">],</span>
                    <span class="p">}</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">keypoint</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">keypoints</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">coco_results</span>

<span class="k">def</span> <span class="nf">convert_to_xywh</span><span class="p">(</span><span class="n">boxes</span><span class="p">):</span>
    <span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">.</span><span class="nf">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">((</span><span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">-</span> <span class="n">ymin</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="n">img_ids</span><span class="p">,</span> <span class="n">eval_imgs</span><span class="p">):</span>
    <span class="n">all_img_ids</span> <span class="o">=</span> <span class="nf">all_gather</span><span class="p">(</span><span class="n">img_ids</span><span class="p">)</span>
    <span class="n">all_eval_imgs</span> <span class="o">=</span> <span class="nf">all_gather</span><span class="p">(</span><span class="n">eval_imgs</span><span class="p">)</span>

    <span class="n">merged_img_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">all_img_ids</span><span class="p">:</span>
        <span class="n">merged_img_ids</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="n">merged_eval_imgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">all_eval_imgs</span><span class="p">:</span>
        <span class="n">merged_eval_imgs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="n">merged_img_ids</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">merged_img_ids</span><span class="p">)</span>
    <span class="n">merged_eval_imgs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">merged_eval_imgs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># keep only unique (and in sorted order) images
</span>    <span class="n">merged_img_ids</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">merged_img_ids</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">merged_eval_imgs</span> <span class="o">=</span> <span class="n">merged_eval_imgs</span><span class="p">[...,</span> <span class="n">idx</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">merged_img_ids</span><span class="p">,</span> <span class="n">merged_eval_imgs</span>

<span class="k">def</span> <span class="nf">create_common_coco_eval</span><span class="p">(</span><span class="n">coco_eval</span><span class="p">,</span> <span class="n">img_ids</span><span class="p">,</span> <span class="n">eval_imgs</span><span class="p">):</span>
    <span class="n">img_ids</span><span class="p">,</span> <span class="n">eval_imgs</span> <span class="o">=</span> <span class="nf">merge</span><span class="p">(</span><span class="n">img_ids</span><span class="p">,</span> <span class="n">eval_imgs</span><span class="p">)</span>
    <span class="n">img_ids</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">img_ids</span><span class="p">)</span>
    <span class="n">eval_imgs</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">eval_imgs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">())</span>

    <span class="n">coco_eval</span><span class="p">.</span><span class="n">evalImgs</span> <span class="o">=</span> <span class="n">eval_imgs</span>
    <span class="n">coco_eval</span><span class="p">.</span><span class="n">params</span><span class="p">.</span><span class="n">imgIds</span> <span class="o">=</span> <span class="n">img_ids</span>
    <span class="n">coco_eval</span><span class="p">.</span><span class="n">_paramsEval</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">coco_eval</span><span class="p">.</span><span class="n">params</span><span class="p">)</span>

<span class="c1">#################################################################
# From pycocotools, just removed the prints and fixed
# a Python3 bug about unicode not defined
#################################################################
</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Run per image evaluation on given images and store results (a list of dict) in self.evalImgs
    :return: None
    </span><span class="sh">'''</span>
    <span class="c1"># tic = time.time()
</span>    <span class="c1"># print('Running per image evaluation...')
</span>    <span class="n">p</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">params</span>
    <span class="c1"># add backward compatibility if useSegm is specified in params
</span>    <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">useSegm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">p</span><span class="p">.</span><span class="n">iouType</span> <span class="o">=</span> <span class="sh">'</span><span class="s">segm</span><span class="sh">'</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">useSegm</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="sh">'</span><span class="s">bbox</span><span class="sh">'</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">useSegm (deprecated) is not None. Running {} evaluation</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">iouType</span><span class="p">))</span>
    <span class="c1"># print('Evaluate annotation type *{}*'.format(p.iouType))
</span>    <span class="n">p</span><span class="p">.</span><span class="n">imgIds</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">imgIds</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">useCats</span><span class="p">:</span>
        <span class="n">p</span><span class="p">.</span><span class="n">catIds</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">catIds</span><span class="p">))</span>
    <span class="n">p</span><span class="p">.</span><span class="n">maxDets</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">maxDets</span><span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">p</span>

    <span class="n">self</span><span class="p">.</span><span class="nf">_prepare</span><span class="p">()</span>
    <span class="c1"># loop through images, area range, max detection number
</span>    <span class="n">catIds</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">catIds</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">useCats</span> <span class="k">else</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">iouType</span> <span class="o">==</span> <span class="sh">'</span><span class="s">segm</span><span class="sh">'</span> <span class="ow">or</span> <span class="n">p</span><span class="p">.</span><span class="n">iouType</span> <span class="o">==</span> <span class="sh">'</span><span class="s">bbox</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">computeIoU</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">computeIoU</span>
    <span class="k">elif</span> <span class="n">p</span><span class="p">.</span><span class="n">iouType</span> <span class="o">==</span> <span class="sh">'</span><span class="s">keypoints</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">computeIoU</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">computeOks</span>
    <span class="n">self</span><span class="p">.</span><span class="n">ious</span> <span class="o">=</span> <span class="p">{</span>
        <span class="p">(</span><span class="n">imgId</span><span class="p">,</span> <span class="n">catId</span><span class="p">):</span> <span class="nf">computeIoU</span><span class="p">(</span><span class="n">imgId</span><span class="p">,</span> <span class="n">catId</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">imgId</span> <span class="ow">in</span> <span class="n">p</span><span class="p">.</span><span class="n">imgIds</span>
        <span class="k">for</span> <span class="n">catId</span> <span class="ow">in</span> <span class="n">catIds</span><span class="p">}</span>

    <span class="n">evaluateImg</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">evaluateImg</span>
    <span class="n">maxDet</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">maxDets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">evalImgs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nf">evaluateImg</span><span class="p">(</span><span class="n">imgId</span><span class="p">,</span> <span class="n">catId</span><span class="p">,</span> <span class="n">areaRng</span><span class="p">,</span> <span class="n">maxDet</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">catId</span> <span class="ow">in</span> <span class="n">catIds</span>
        <span class="k">for</span> <span class="n">areaRng</span> <span class="ow">in</span> <span class="n">p</span><span class="p">.</span><span class="n">areaRng</span>
        <span class="k">for</span> <span class="n">imgId</span> <span class="ow">in</span> <span class="n">p</span><span class="p">.</span><span class="n">imgIds</span>
    <span class="p">]</span>
    <span class="c1"># this is NOT in the pycocotools code, but could be done outside
</span>    <span class="n">evalImgs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">evalImgs</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">catIds</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">areaRng</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">imgIds</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="n">_paramsEval</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">params</span><span class="p">)</span>
    <span class="c1"># toc = time.time()
</span>    <span class="c1"># print('DONE (t={:0.2f}s).'.format(toc-tic))
</span>    <span class="k">return</span> <span class="n">p</span><span class="p">.</span><span class="n">imgIds</span><span class="p">,</span> <span class="n">evalImgs</span>

<span class="c1">#################################################################
# end of straight copy from pycocotools, just removing the prints
#################################################################
</span></pre></table></code></div></div></details><h2 id="p35-其他函数">P3.5 其他函数</h2><h3 id="p351-box_cxcywh_to_xyxy">P3.5.1 box_cxcywh_to_xyxy</h3><p>位于util/box_ops.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_c</span><span class="p">,</span> <span class="n">y_c</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x_c</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">w</span><span class="p">),</span> <span class="p">(</span><span class="n">y_c</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">h</span><span class="p">),</span>
         <span class="p">(</span><span class="n">x_c</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">w</span><span class="p">),</span> <span class="p">(</span><span class="n">y_c</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">h</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></table></code></div></div></details><h3 id="p352-box_xyxy_to_cxcyw">P3.5.2 box_xyxy_to_cxcyw</h3><p>位于util/box_ops.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">box_xyxy_to_cxcywh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x0</span> <span class="o">+</span> <span class="n">x1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">y0</span> <span class="o">+</span> <span class="n">y1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span>
         <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x0</span><span class="p">),</span> <span class="p">(</span><span class="n">y1</span> <span class="o">-</span> <span class="n">y0</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></table></code></div></div></details><h3 id="p353-nestedtensor">P3.5.3 NestedTensor</h3><p>NestedTensor包含tensor和mask。tensor为输入的图像：BCHW，mask为BHW（pad的位置为True，原始图像位置为False，后面使用时会取反：pad位置为False，原始图像位置为True）。tensors为整个batch里面最大的w，h，用0 padding补齐（右，下padding）。位于util/misc.py</p><details><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">_max_by_axis</span><span class="p">(</span><span class="n">the_list</span><span class="p">):</span>  <span class="c1"># 返回2维the_list中每个维度最大的结果（即返回多个CHW的list中最大的CHW的list）
</span>    <span class="c1"># type: (List[List[int]]) -&gt; List[int]
</span>    <span class="n">maxes</span> <span class="o">=</span> <span class="n">the_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">the_list</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">sublist</span><span class="p">):</span>
            <span class="n">maxes</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">maxes</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">item</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">maxes</span>

<span class="k">class</span> <span class="nc">NestedTensor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tensors</span> <span class="o">=</span> <span class="n">tensors</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="c1"># type: (Device) -&gt; NestedTensor # noqa
</span>        <span class="n">cast_tensor</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tensors</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">mask</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
            <span class="n">cast_mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cast_mask</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">return</span> <span class="nc">NestedTensor</span><span class="p">(</span><span class="n">cast_tensor</span><span class="p">,</span> <span class="n">cast_mask</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decompose</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">tensors</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">mask</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">str</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">tensors</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">nested_tensor_from_tensor_list</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]):</span>   <span class="c1"># 将当前batch中不同宽高的图像转成相同宽高（贴到最大图像左上角），并返回NestedTensor类型的数据
</span>    <span class="c1"># TODO make this more general
</span>    <span class="k">if</span> <span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">torchvision</span><span class="p">.</span><span class="nf">_is_tracing</span><span class="p">():</span>
            <span class="c1"># nested_tensor_from_tensor_list() does not export well to ONNX
</span>            <span class="c1"># call _onnx_nested_tensor_from_tensor_list() instead
</span>            <span class="k">return</span> <span class="nf">_onnx_nested_tensor_from_tensor_list</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">)</span>

        <span class="c1"># TODO make it support different-sized images
</span>        <span class="n">max_size</span> <span class="o">=</span> <span class="nf">_max_by_axis</span><span class="p">([</span><span class="nf">list</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">])</span>  <span class="c1"># 返回多个CHW的list中最大的CHW的list
</span>        <span class="c1"># min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))
</span>        <span class="n">batch_shape</span> <span class="o">=</span> <span class="p">[</span><span class="nf">len</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">)]</span> <span class="o">+</span> <span class="n">max_size</span>  <span class="c1"># BCHW的值
</span>        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">batch_shape</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">dtype</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">device</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">pad_img</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
            <span class="n">pad_img</span><span class="p">[:</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]].</span><span class="nf">copy_</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>   <span class="c1"># batch中每张图像拷贝到更大的缓冲区中的左上角
</span>            <span class="n">m</span><span class="p">[:</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">False</span>    <span class="c1"># mask的图像区域为False
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sh">'</span><span class="s">not supported</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="nc">NestedTensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>   <span class="c1"># 返回NestedTensor类型的数据
</span>
<span class="c1"># _onnx_nested_tensor_from_tensor_list() is an implementation of
# nested_tensor_from_tensor_list() that is supported by ONNX tracing.
</span><span class="nd">@torch.jit.unused</span>
<span class="k">def</span> <span class="nf">_onnx_nested_tensor_from_tensor_list</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NestedTensor</span><span class="p">:</span>
    <span class="n">max_size</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">dim</span><span class="p">()):</span>
        <span class="n">max_size_i</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">max_size</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">max_size_i</span><span class="p">)</span>
    <span class="n">max_size</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="n">max_size</span><span class="p">)</span>

    <span class="c1"># work around for
</span>    <span class="c1"># pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)
</span>    <span class="c1"># m[: img.shape[1], :img.shape[2]] = False
</span>    <span class="c1"># which is not yet supported in onnx
</span>    <span class="n">padded_imgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">padded_masks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="p">[(</span><span class="n">s1</span> <span class="o">-</span> <span class="n">s2</span><span class="p">)</span> <span class="k">for</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">max_size</span><span class="p">,</span> <span class="nf">tuple</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">))]</span>
        <span class="n">padded_img</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">padded_imgs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">padded_img</span><span class="p">)</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">img</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">padded_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="sh">"</span><span class="s">constant</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">padded_masks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">padded_mask</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">))</span>

    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">padded_imgs</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">padded_masks</span><span class="p">)</span>

    <span class="k">return</span> <span class="nc">NestedTensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</pre></table></code></div></div></details><h1 id="a-附录">A. 附录</h1><h2 id="a1-多头注意力层">A.1 多头注意力层</h2><p>注意力机制和<a href="https://arxiv.org/abs/1808.04444">https://arxiv.org/abs/1808.04444</a>一致，除了位置编码和<a href="https://arxiv.org/abs/1911.03584">https://arxiv.org/abs/1911.03584</a>一致。 多头：有M个头且通道数为d的多头注意力机制如下（ \(d'=\frac{d}{M}\) ，下标给出了矩阵/张量大小。注意，原论文中此处为公式3）：</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/post/2021-08-21-DETR/a1.png" alt="a1" width="400" /></p><p>(5)</p><p>其中 \({ {X}_{q}}\) 为长度为 \({ {N}_{q}}\) 的query sequence， \({ {X}_{kv}}\) 为长度为 \({ {N}_{kv}}\) 的key-value sequence（为简化，使用相同数量的通道d），T为计算query, key and value embeddings的权重张量，L为投影矩阵。输出和query sequence大小相同。多头自注意力（mh-s-attn）为 \({ {X}_{q}}={ {X}_{kv}}\) 的特殊情况（注意，原论文中此处为公式4）：</p>\[\text{mh-s-attn}(X,T,L)=\text{mh-attn}(X,X,T,L) \tag{6}\]<p>多头注意力为M个单头注意力拼接，并加上一个投影矩阵L。<a href="https://arxiv.org/abs/1808.04444">https://arxiv.org/abs/1808.04444</a>中使用残差连接、dropout和layer-norm。换句话说，定义 \({ {\tilde{X}}_{q}}=\text{mh-attn}({ {X}_{q}},{ {X}_{kv}},T,L)\) ，且 \({ {\bar{\bar{X}}}^{\left( q \right)}}\) 为注意力头的拼接，则（注意，原论文中此处为公式5, 6）：</p>\[X_{q}^{'}=\left[ \text{mh-attn}({ {X}_{q}},{ {X}_{kv}},{ {T}_{1}});\ldots ;\text{mh-attn}({ {X}_{q}},{ {X}_{kv}},{ {T}_{M}}) \right] \tag{7}\] \[{ {\tilde{X}}_{q}}=\text{layernorm}\left( { {X}_{q}}+dropout\left( LX_{q}^{'} \right) \right) \tag{8}\]<p>其中 \(\left[ ; \right]\) 代表在通道维度拼接。</p><p>说明：论文中这样定义，但是感觉 \({ {\bar{\bar{X}}}^{\left( q \right)}}\) 即指公式7中的 \(X_{q}^{'}\) 。</p><p><strong>单头</strong>：使用权重张量 \(T'\in { {\mathbb{R}}^{3\times d'\times d}}\) 的注意力头，表示为 \(\text{attn}\left( { {X}_{q}},{ {X}_{kv}},T' \right)\) ，依赖额外的位置编码 \({ {P}_{q}}\in { {\mathbb{R}}^{d\times { {N}_{q}}}}\) 和 \({ {P}_{kv}}\in { {\mathbb{R}}^{d\times { {N}_{kv}}}}\) 。在加上query和key的位置编码之后，其通过下式计算query, key and value embeddings（见论文<a href="https://arxiv.org/abs/1911.0358">https://arxiv.org/abs/1911.0358</a>。注意，原论文中此处为公式7）：</p>\[\left[ Q;K;V \right]=\left[ T_{1}^{'}\left( { {X}_{q}}+{ {P}_{q}} \right);T_{2}^{'}\left( { {X}_{kv}}+{ {P}_{kv}} \right);T_{3}^{'}{ {X}_{kv}} \right] \tag{9}\]<p>其中 \(T'\) 为 \(T_{1}^{'},T_{2}^{'},T_{3}^{'}\) 的拼接。注意力权重（attention weights） \({\alpha }\) 通过queries和keys点乘并通过softmax得到，这样query sequence的每个元素都会和key-value sequence的所有元素相关（i为query的索引，j为key-value的索引。注意，原论文中此处为公式8）</p>\[{ {\alpha }_{i,j}}=\frac{ { {e}^{\frac{1}{\sqrt{d'}}Q_{i}^{T}{ {K}_{j}}}}}{ { {Z}_{i}}}\text{ , }\text{ }{ {Z}_{i}}\text{=}\sum\limits_{j=1}^{ { {N}_{kv}}}{ { {e}^{\frac{1}{\sqrt{d'}}Q_{i}^{T}{ {K}_{j}}}}} \tag{10}\]<p>该文中，位置编码可以学习到或者固定该值，但是对于给定的query/key-value sequence都在所有注意力层共享，因而该文不明确得把它们作为注意力的参数。在描述编码器和解码器时，该文给出了关于其精确值的更多细节。最终输出是由注意力权重加权之和：第i行为 \(\text{att}{ {\text{n}}_{i}}\left( { {X}_{q}},{ {X}_{kv}},T' \right)=\sum\nolimits_{j=1}^{ { {N}_{kv}}}{ { {\alpha }_{i,j}}{ {V}_{j}}}\)</p><p><strong>前向神经网络层（Feed-forward network layers, FFN）</strong>：原始的FFN层使用多层1<em>1卷积，在本文情况下有Md个输入和输出通道。本文使用的FFN由2层1</em>1卷积核ReLU组成。另外在两层后也有残差连接/dropout/layernorm，和公式8类似。</p><h2 id="a2-损失">A.2 损失</h2><p>该文中所有的损失都通道当前batch中目标的个数进行归一化。分布式计算中需要注意：由于每个GPU都使用子batch，由于每个子batch中目标个数不均衡，因而不能使用子batch中目标个数归一化，而应该使用所有子batch目标总数进行归一化。</p><p><strong>目标框损失</strong>：损失中使用generalized IoU（GIoU）加上L1损失（注意，原论文中此处为公式9）：</p>\[{ {L}_{box}}\left( { {b}_{\sigma \left( i \right)}},{ { {\hat{b}}}_{i}} \right)={ {\lambda }_{iou}}{ {L}_{iou}}\left( { {b}_{\sigma \left( i \right)}},{ { {\hat{b}}}_{i}} \right)+{ {\lambda }_{L1}}\left\| { {b}_{\sigma \left( i \right)}}-{ { {\hat{b}}}_{i}} \right\| \tag{11}\]<p>其中 \({ {\lambda }_{iou}},{ {\lambda }_{L1}}\in \mathbb{R}\) 为超参， \({ {L}_{iou}}\left( \centerdot \right)\) 为GIoU（注意，原论文中此处为公式10）： \({ {L}_{iou}}\left( { {b}_{\sigma \left( i \right)}},{ { {\hat{b}}}_{i}} \right)\text{=}1-\left( \frac{\left| { {b}_{\sigma \left( i \right)}}\bigcap { { {\hat{b}}}_{i}} \right|}{\left| { {b}_{\sigma \left( i \right)}}\bigcup { { {\hat{b}}}_{i}} \right|}-\frac{\left| B\left( { {b}_{\sigma \left( i \right)}},{ { {\hat{b}}}_{i}} \right)\backslash { {b}_{\sigma \left( i \right)}}\bigcup { { {\hat{b}}}_{i}} \right|}{\left| B\left( { {b}_{\sigma \left( i \right)}},{ { {\hat{b}}}_{i}} \right) \right|} \right) \tag{12}\) 其中 \(\left| \centerdot \right|\) 表示面积，交集和并集的面积通过线性函数 \({ {b}_{\sigma \left( i \right)}}\) 和 \(\hat{b}\) 的min/max计算，使得损失对随机梯度表现得足够好。 \(B\left( { {b}_{\sigma \left( i \right)}},{ { {\hat{b}}}_{i}} \right)\) 代表包含 \({ {b}_{\sigma \left( i \right)}}\) 和 \(\hat{b}\) 的最大的框。</p><p><strong>DICE/F-1 loss</strong>：DICE系数（<a href="https://arxiv.org/abs/1606.04797">https://arxiv.org/abs/1606.04797</a>）与IoU密切相关。如果定义 \(\hat{m}\) 为模型的raw mask logits prediction，并且m为模型的binary target mask，损失定义为（注意，原论文中此处为公式11）：</p>\[{ {L}_{DICE}}\left( m,\hat{m} \right)=1-\frac{2m\sigma \left( {\hat{m}} \right)+1}{\sigma \left( {\hat{m}} \right)+m+1} \tag{13}\]<p>其中 \({\sigma }\) 为sigmoid函数。该损失通过目标数量进行归一化。</p><h2 id="a3-详细结构">A.3 详细结构</h2><p>图3列出了DETR中使用的transformer和每个注意力层使用的位置编码的具体结构。图像通过CNN骨干网络得到的特征传入transformer编码子网络和在每个多头自自注意力层传入queries and keys的空间位置编码子网络。之后，queries传入解码器（初始化为0），输出位置编码（object queries），并且通过多个多头自注意力和解码器-编码器注意力层得到最终的预测类别和边界框。能够跳过第一个解码器层的第一个自注意力层。</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/post/2021-08-21-DETR/3.png" alt="3" /> <em>图3</em></p></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div class="post-tags"> <span>标签(Tags)</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >deep learning</a> <a href="/tags/algorithm/" class="post-tag no-text-decoration" >algorithm</a> <a href="/tags/transformers/" class="post-tag no-text-decoration" >transformers</a></div></div><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/UbuntuAgent/">Ubuntu使用代理</a><li><a href="/posts/SunloginDisconnectWin10/">windows10使用向日葵访问ubuntu 20.04显示连接已断开</a><li><a href="/posts/TimeWin10Ubuntu/">windows10和ubuntu双系统的时间差</a><li><a href="/posts/markdown/">markdown基本语法</a><li><a href="/posts/MountDriverInWin10Ubuntu/">windows10的ubuntu子系统挂载移动硬盘</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/detection/">detection</a> <a class="post-tag" href="/tags/normalization/">normalization</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/transformers/">transformers</a> <a class="post-tag" href="/tags/demo/">demo</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h6 align="left"><br>未设置提醒，因而不一定能看到回复，见谅</h6><div class="post-navigation d-flex justify-content-between"> <a href="/posts/EANet/" class="btn btn-outline-primary" prompt="Older"><p>EANet Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks</p></a> <a href="/posts/CenterNet/" class="btn btn-outline-primary" prompt="Newer"><p>CenterNet Objects as Points</p></a></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script> <script src="https://code.jquery.com/jquery-3.2.0.min.js"></script> <script>AV.initialize("7DUQTBuCCKLjnutJOa6ko5cn-MdYXbMMI", "lxmthTQ8ESa2HrVQiIVyXtYo");</script> <script> //新增访问次数 function addCount(Counter) { // 页面（博客文章）中的信息：leancloud_visitors // id为page.url， data-flag-title为page.title var $visitors = $(".leancloud_visitors"); var url = $visitors.attr('id').trim(); var title = $visitors.attr('data-flag-title').trim(); var query = new AV.Query(Counter); // 只根据文章的url查询LeanCloud服务器中的数据 query.equalTo("post_url", url); query.find({ success: function(results) { if (results.length > 0) {//说明LeanCloud中已经记录了这篇文章 var counter = results[0]; counter.fetchWhenSave(true); counter.increment("visited_times");// 将点击次数加1 counter.save(null, { success: function(counter) { var $element = $(document.getElementById(url)); var newTimes = counter.get('visited_times'); $element.find('.leancloud-visitors-count').text(newTimes); }, error: function(counter, error) { console.log('Failed to save Visitor num, with error message: ' + error.message); } }); } else { // 执行这里，说明LeanCloud中还没有记录此文章 var newcounter = new Counter(); /* Set ACL */ var acl = new AV.ACL(); acl.setPublicReadAccess(true); acl.setPublicWriteAccess(true); newcounter.setACL(acl); /* End Set ACL */ newcounter.set("post_title", title);// 把文章标题 newcounter.set("post_url", url); // 文章url newcounter.set("visited_times", 1); // 初始点击次数：1次 newcounter.save(null, { // 上传到LeanCloud服务器中 success: function(newcounter) { var $element = $(document.getElementById(url)); var newTimes = newcounter.get('visited_times'); $element.find('.leancloud-visitors-count').text(newTimes); }, error: function(newcounter, error) { console.log('Failed to create'); } }); } }, error: function(error) { console.log('Error:' + error.code + " " + error.message); } }); } //仅根据url和title查出当前访问次数，不做+1操作 function showCount(Counter) { var $visitors = $(".leancloud_visitors"); var url = $visitors.attr('id').trim(); var title = $visitors.attr('data-flag-title').trim(); var query = new AV.Query(Counter); // 只根据文章的url查询LeanCloud服务器中的数据 query.equalTo("post_url", url); query.find({ success: function(results) { if (results.length > 0) {//说明LeanCloud中已经记录了这篇文章 var counter = results[0]; var $element = $(document.getElementById(url)); var newTimes = counter.get('visited_times'); $element.find('.leancloud-visitors-count').text(newTimes); } else { //如果表里没查到记录，那就是异常情况了 console.log('异常情况，不应该没记录的'); } }, error: function(error) { console.log('Error:' + error.code + " " + error.message); } }); } //调用API获取IP function getVisitorIpAndJudge() { var ip; var options = { type: 'POST', dataType: "json", //async: false, //jquery3中可以直接使用回调函数，不用再指定async url: "https://freegeoip.net/json/?callback=?" }; $.ajax(options) .done(function(data, textStatus, jqXHR) { if(textStatus == "success") { ip = data.ip; } judgeVisitor(ip) }); } //判断访客是否已访问过该文章，及访问时间，符合条件则增加一次访问次数 function judgeVisitor(ip) { var Counter = AV.Object.extend("visited_times"); var Visitor = AV.Object.extend("visitors_record"); var $postInfo = $(".leancloud_visitors"); var post_url = $postInfo.attr('id').trim(); var query = new AV.Query(Visitor); query.equalTo("visitor_ip", ip); query.equalTo("post_url", post_url); query.find({ success: function(results) { if (results.length > 0) { console.log('该IP已访问过该文章'); var oldVisitor = results[0]; var lastTime = oldVisitor.updatedAt; var curTime = new Date(); var timePassed = curTime.getTime() - lastTime.getTime(); if(timePassed > 1 * 60 * 1000) { console.log('距离该IP上一次访问该文章已超过了1分钟，更新访问记录，并增加访问次数'); addCount(Counter); oldVisitor.fetchWhenSave(true); oldVisitor.save(null, { success: function(oldVisitor) { }, error: function(oldVisitor, error) { console.log('Failed to save visitor record, with error message: ' + error.message); } }); } else { console.log('这是该IP 1分钟内重复访问该文章，不更新访问记录，不增加访问次数'); showCount(Counter); } } else { console.log('该IP第一次访问该文章，保存新的访问记录，并增加访问次数'); addCount(Counter); var newVisitor = new Visitor(); /* Set ACL */ var acl = new AV.ACL(); acl.setPublicReadAccess(true); acl.setPublicWriteAccess(true); newVisitor.setACL(acl); newVisitor.set("visitor_ip", ip); newVisitor.set("post_url", post_url); newVisitor.save(null, { // 上传到LeanCloud服务器中 success: function(newVisitor) { }, error: function(newVisitor, error) { console.log('Failed to create visitor record, with error message: ' + error.message); } }); } }, error: function(error) { console.log('Error:' + error.code + " " + error.message); addCount(Counter); } }); } $(function() { if ($('.leancloud_visitors').length == 1) { // 文章页面，调用判断方法，对符合条件的访问增加访问次数 getVisitorIpAndJudge(); } else if ($('.post-link').length > 1){ // 首页 暂未使用 // showHitCount(Counter); } }); </script><div> <span id="/posts/DETR/" class="leancloud_visitors" data-flag-title="DETR End-to-End Object Detection with Transformers"> <a href="#">Pageviews:<span class="leancloud-visitors-count"></span> times</a></span></div><h4 align="left">用户留言：</h4><div id="comments"></div><script src='//unpkg.com/valine/dist/Valine.min.js'></script> <script> new Valine({ av: AV, el: '#comments', app_id: '7DUQTBuCCKLjnutJOa6ko5cn-MdYXbMMI', app_key: 'lxmthTQ8ESa2HrVQiIVyXtYo', placeholder: '', avatar: 'mp', notify: 'true', verify: 'true', recordIP: 'true', enableQQ: 'true', visitor: true }); </script></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#main > div.row:first-child > div:first-child img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="">darkknightzh</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/detection/">detection</a> <a class="post-tag" href="/tags/normalization/">normalization</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/transformers/">transformers</a> <a class="post-tag" href="/tags/demo/">demo</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://darkknightzh.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
