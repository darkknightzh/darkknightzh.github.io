[ { "title": "强化学习之q-learning", "url": "/posts/qlearning/", "categories": "", "tags": "linux", "date": "2025-03-28 14:30:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/qlearning参考网址：https://www.cnblogs.com/chase-youth/p/18110374https://www.datacamp.com/tutorial/introduction-q-learning-beginner-tutorialhttps://zhuanlan.zhihu.com/p/74065749P1. 简介Q-learning是一种无模型、基于值的非策略算法，其根据agent的当前状态找到最佳行为。“Q”意为quality，代表了action在最大化未..." }, { "title": "windows10使用向日葵访问ubuntu 20.04显示连接已断开", "url": "/posts/SunloginDisconnectWin10/", "categories": "", "tags": "linux", "date": "2021-11-11 14:50:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/SunloginDisconnectWin10参考网址：https://zhuanlan.zhihu.com/p/281051791https://www.cnblogs.com/xlpc/p/12345478.htmlhttps://zhuanlan.zhihu.com/p/281051791指出：sudo apt updatesudo apt upgradesudo apt install lightdm选择lightdm即可，需要重启。若此时未选择lightdm，而是gdm3，则输入如下命令，..." }, { "title": "Ubuntu使用ppa源安装显卡驱动", "url": "/posts/UbuntuPPANvidia/", "categories": "", "tags": "linux", "date": "2021-11-11 14:30:00 +0800", "snippet": "可使用https://blog.csdn.net/wanghaoranand/article/details/96443874中方法使用命令安装。也可以在终端中输入下面命令，而后在系统设置-软件和更新-附件驱动中直接选择相应版本的驱动。sudo add-apt-repository ppa:graphics-drivers/ppa" }, { "title": "Ubuntu使用代理", "url": "/posts/UbuntuAgent/", "categories": "", "tags": "linux", "date": "2021-11-11 14:30:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/UbuntuAgent参考网址：http://loonlog.com/2020/10/5/v2ray-server-new/https://github.com/jiangxufeng/v2rayLhttps://bella722.github.io/post/a2e7ced5.htmlhttps://zhuanlan.zhihu.com/p/46973701说明：使用代理请用于学习，请勿用于发表和从事任何不利于国家安全、民族团结和国家复兴的言论和行为。P1 配置代理1 配置代理服务器，安装v2ra..." }, { "title": "windows10和ubuntu双系统的时间差", "url": "/posts/TimeWin10Ubuntu/", "categories": "", "tags": "linux", "date": "2021-11-11 14:00:00 +0800", "snippet": "原始网址：https://www.cnblogs.com/chengjue924/p/8915758.htmlsudo apt-get install ntpdatesudo ntpdate time.windows.comsudo hwclock --localtime --systohc" }, { "title": "windows10的ubuntu子系统挂载移动硬盘", "url": "/posts/MountDriverInWin10Ubuntu/", "categories": "", "tags": "linux", "date": "2021-11-01 15:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/MountDriverInWin10Ubuntu原始英文网址：https://linuxnightly.com/mount-and-access-hard-drives-in-windows-subsystem-for-linux-wsl/win10上安装ubuntu 20的子系统后，在/mnt目录下，能直接访问c，d等系统盘（不过win上大小写都行，ubuntu上只有小写才能访问）。但是若电脑连接了移动硬盘，则/mnt目录下有相应盘符（如电脑移动硬盘为E，则/mnt下有e目录，但直接进去是空文件夹..." }, { "title": "Patches Are All You Need?", "url": "/posts/ConvMixer/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-10-29 15:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/ConvMixer论文：https://openreview.net/pdf?id=TVHS5Y4dNvM官方pytorch代码：https://github.com/tmp-iclr/convmixerP1. 摘要ViT需要使用patch embeddings，将图像的小区域组合成特征，这样方便应用到大图像上。而该文探讨了如下问题：ViT的强大性能是否更多地来自基于patch的表示，而不是来自Transformer结构本身？该文给出的结果是：是的。并且提出了ConvMixer，直接将图像块作为输入..." }, { "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks", "url": "/posts/fasterRCNN/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2021-09-20 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/fasterRCNN论文：https://arxiv.org/abs/1506.01497之前的第三方代码解释：https://www.cnblogs.com/darkknightzh/p/10043864.htmlhttps://darkknightzh.github.io/posts/fasterRCNNcodeP1. 简介Faster R-CNN包括两个模块：用于提供候选区域的FCN网络（称作RPN，Region Proposal Network），使用该候选区域的Fast R-CNN检测器。..." }, { "title": "目标检测中的一些评价参数", "url": "/posts/detectionMetrics/", "categories": "", "tags": "detection", "date": "2021-09-13 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/detectionMetrics参考网址：（基本上都是从下面网址中复制，因而可以直接去相应网址查看）https://blog.csdn.net/CherDW/article/details/55813071https://www.jianshu.com/p/5df19746daf9https://blog.csdn.net/sinat_42239797/article/details/93651594https://blog.csdn.net/u013063099/article/details/8..." }, { "title": "markdown基本语法", "url": "/posts/markdown/", "categories": "", "tags": "demo", "date": "2021-08-30 15:50:00 +0800", "snippet": "说明：该文仅用于写文档时参考格式。文本Text can be bold, italic, or strikethrough. Links should be blue with no underlines (unless hovered over).Header 1（一级标题下面默认带横线）Header 2Header 3Header 4Header 5Header 6上下均有一条横线 3个及其以上的*-_，但彼此之间不能混用换1行Ordered list Firstly SecondlyUnordered list Chapter 1 Setcion 1 ..." }, { "title": "YOLOv3: An Incremental Improvement", "url": "/posts/YOLOV3/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2021-08-26 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/YOLOV3论文：https://arxiv.org/abs/1804.02767官方代码：https://pjreddie.com/darknet/yolo/YOLOv3是对v2版本的改进，做了一些小的修改，使其性能更好。边界框预测和YOLO9000一样，使用k-means确定的候选框形状作为anchor。网络预测每个边界框的\\({ {t}_{x}}\\)，\\({ {t}_{y}}\\)，\\({ {t}_{w}}\\)，\\({ {t}_{h}}\\)这4个坐标。如果当前目标所在网格距离图像左上角\\(\\le..." }, { "title": "YOLOV2 YOLO9000: Better, Faster, Stronger", "url": "/posts/YOLOV2/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2021-08-26 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/YOLOV2论文：https://arxiv.org/abs/1612.08242和Fast R-CNN相比，YOLO目标定位错误多很多。和基于候选区域的方法相比，YOLO召回率低。因而该文提出YOLOv2和YOLO9000，在保持分类精度的前提下，提高召回率和定位精度。采用Darknet-19的骨干网络，使用BatchNorm，并分别使用224*224和448*448两阶段ImageNet预训练模型进行微调。引入anchor机制，使用K-Means在训练集中积累出更好的anchor模板，提高了召回..." }, { "title": "YOLOV1 You Only Look Once: Unified, Real-Time Object Detection", "url": "/posts/YOLOV1/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2021-08-25 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/YOLOV1论文：https://arxiv.org/abs/1506.02640YOLO是深度学习的第一个一阶段检测器。其将单个神经网络应用到整个图像，将图像调整到448*448，分割成7*7的网格，提取特征，直接预测每个网格的边界框坐标和每个类别的置信度（有什么目标，是这个目标的置信度）。训练时使用leaky ReLU激活函数，测试时使用NMS去除重叠的框。该文提出YOLO（YOLOv1），该系统将输入图像分成S*S的网格。如果目标中心在某个网格中，该网格用于检测该目标。每个网格预测B个边界框和..." }, { "title": "MTCNN Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks", "url": "/posts/MTCNN/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2021-08-24 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/MTCNN论文：https://arxiv.org/abs/1604.02878第三方pytorch代码：https://github.com/timesler/facenet-pytorchP1. 摘要该文提出MTCNN，一个级联的CNN结构，能检测人脸并得到人脸关键点信息。其包括三个阶段。第一阶段通过若干层CNN网络得到候选人脸框。第二阶段通过更复杂的CNN网络，优化候选框，去除大量非人脸窗。第三阶段，通过更强大的CNN网络进一步优化检测结果并输出人脸面部关键点信息。P2. MTCNNP2.1 ..." }, { "title": "CornerNet: Detecting Objects as Paired Keypoints", "url": "/posts/CornerNet/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2021-08-24 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/CornerNetCornerNet论文：https://arxiv.org/abs/1808.01244CornerNet-Lite论文：https://arxiv.org/abs/1904.08900官方CornerNet-Lite的pytorch代码：https://github.com/princeton-vl/CornerNet-Lite说明：本文为cornernet的理解。但代码看的是CornerNet-Lite，不太匹配。。。P1. 简介该文提出CornerNet，一个不需要ancho..." }, { "title": "SSD Single Shot MultiBox Detector", "url": "/posts/SSD/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2021-08-23 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/SSD论文：https://arxiv.org/abs/1512.02325第三方pytorch代码：https://github.com/amdegroot/ssd.pytorchP1. 简介SSD（Single Shot MultiBox Detector）由W. Liu等人于2015年提出，比之前的SOTA的一阶段的检测算法YOLO更快，切更准确，同时和二阶段的检测算法，如Faster R-CNN准确度相近。它相比起YOLO v1 主要的改进点在于两个方面：1. 利用了先验框（Prior Bo..." }, { "title": "CenterNet Objects as Points", "url": "/posts/CenterNet/", "categories": "", "tags": "deep learning, algorithm, detection, detection", "date": "2021-08-23 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/CenterNet论文：https://arxiv.org/abs/1904.07850官方代码：https://github.com/xingyizhou/CenterNetP1. 摘要CenterNet为anchor-free的方法。如图1所示，本文将目标建模为其边界框的中心点。边界框的大小和其他属性可以通过目标中心关键点的特征推断。图1 centernet本文算法可以认为是一个单形不可知的anchor（single shape-agnostic anchor），如图2所示。优点：① Cente..." }, { "title": "DETR End-to-End Object Detection with Transformers", "url": "/posts/DETR/", "categories": "", "tags": "deep learning, algorithm, transformers", "date": "2021-08-21 09:23:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/DETR论文：https://arxiv.org/abs/2005.12872官方pytorch代码：https://github.com/facebookresearch/detrP1.简介该文提出基于Transformer的端到端目标检测算法（DEtection TRansformer, DETR），该算法基于以下算法：用于集合预测的二分图最大匹配损失，基于transformer的编码器-解码器结构，并行解码，目标检测算法。目前常用的两阶段检测器根据候选框预测坐标，一阶段检测器根据anchor或..." }, { "title": "EANet Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks", "url": "/posts/EANet/", "categories": "", "tags": "deep learning, algorithm, transformers", "date": "2021-08-18 18:43:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/EANet论文：https://arxiv.org/abs/2105.02358官方pytorch代码：https://github.com/MenghaoGuo/EANet第三方代码：https://github.com/xmu-xiaoma666/External-Attention-pytorchp1. 简介注意力机制可以看做根据特征激活的重要性重新分配资源的机制。该论文提出external attention：只使用2个线性层和2个归一化层。图1p2. EANetp2.1 自注意力（Self..." }, { "title": "gru", "url": "/posts/gru/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-08-16 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/gru论文：https://arxiv.org/abs/1412.3555参考网址：http://dprogrammer.org/rnn-lstm-gruhttps://gdcoder.com/what-is-a-recurrent-neural-networks-rnns-and-gated-recurrent-unit-grus/https://pytorch.org/docs/stable/generated/torch.nn.GRU.html说明：本文默认均是batch_first=Fals..." }, { "title": "lstm", "url": "/posts/lstm/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-08-13 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/lstm论文：https://www.bioinf.jku.at/publications/older/2604.pdfpytorch中LSTM参考论文：https://arxiv.org/abs/1402.1128参考网址：http://colah.github.io/posts/2015-08-Understanding-LSTMs/https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html说明：本文默认均是batch_first=F..." }, { "title": "rnn", "url": "/posts/rnn/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-08-12 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/rnn参考网址：https://zhuanlan.zhihu.com/p/32103001https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNNhttps://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks说明：① batch_first=False时，输入为：序列长度 * batch size * 特征长度..." }, { "title": "Weight Normalization（WN）", "url": "/posts/weightnorm/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/weightnorm论文：https://arxiv.org/abs/1602.07868① 权重归一化（Weight Normalization）给定k维权重向量w和偏置标量b，以及k维神经元输入向量x，该神经元输出为\\[y=\\phi \\left( \\mathbf{w}\\centerdot \\mathbf{x}+b \\right)\\]其中\\(\\phi \\left( \\centerdot \\right)\\)为激活函数，如ReLU，y为标量输出。一般使用sgd更新参数w和b，为了加速收敛，该文将w重..." }, { "title": "Switchable Normalization（SN）", "url": "/posts/switchablenorm/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/switchablenorm论文：https://arxiv.org/abs/1806.10779官方pytorch代码：https://github.com/ascenoputing/Switchable-Normalization作者之一关于SN的中文解读：https://zhuanlan.zhihu.com/p/39296570该文提出Switchable Normalization，使用加权BN、IN、LN的归一化方法，其中权重是通过训练得到。① 归一化的通用形式假设4D张量h为归一化层的输..." }, { "title": "Layer Normalization（LN）", "url": "/posts/layernorm/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/layernorm论文：https://arxiv.org/abs/1607.06450假设第l层第i个输入为\\(a_{i}^{l}\\)，忽略偏置时，令\\(\\overline{a}_{i}^{l}\\)为l层第i个隐含单元的归一化输入，\\({ {g}^{i}}\\)为增益，即\\[\\overline{a}_{i}^{l}=\\frac{g_{i}^{l}}{\\sigma _{i}^{l}}\\left( a_{i}^{l}-\\mu _{i}^{l} \\right)\\]当时用BN归一化时，\\[\\mu _{i}^..." }, { "title": "Instance Normalization（IN, contrast normalization）", "url": "/posts/instancenorm/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/instancenorm论文：https://arxiv.org/abs/1607.08022Layer Normalization不依赖batch size，统计同层内所有神经元响应值的均值和方差，Instance Normalization则将统计范围进一步缩小到HW维度。令\\(x\\in { {\\mathbb{R}}^{T\\times C\\times W\\times H}}\\)为输入的包含T张图像的张量，其中T为batch size，C为通道数，W为特征宽度，H为特征高度。令\\({ {x}_{t..." }, { "title": "Group Normalization（GN）", "url": "/posts/groupnorm/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/groupnorm论文：https://arxiv.org/abs/1803.08494说明：Batch Norm(BN)，Layer Norm(LN)，Instance Norm(IN)，Group Norm(GN)通用的特征归一化，包括BN，LN，IN和GN，定义如下：\\[{ {\\hat{x}}_{i}}=\\frac{1}{ { {\\sigma }_{i}}}\\left( { {x}_{i}}-{ {\\mu }_{i}} \\right)\\]其中x为输入特征。i为索引，在输入为2D图像是，\\(i=..." }, { "title": "Batch Renormalization（BRN）", "url": "/posts/batchrenorma/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/batchrenorma论文：https://arxiv.org/abs/1702.03275在训练和测试阶段使用BN时，由于归一化方式不同，因而网络的行为也不同。为了解决这个问题，作者提出了Batch Renormalization（BRN），即先对输入x进行仿射变换，然后再通过BN，得到输出。假设网络中某节点为x，其通过最后几次batch得到的均值和标准差分别为\\(\\mu\\)和\\(\\sigma\\)，则\\[\\frac{ { {x}_{i}}-\\mu }{\\sigma }=\\frac{ { {x}_..." }, { "title": "Batch Normalization（BN）", "url": "/posts/batchnorm/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/batchnorm(1) Internal Covariate Shift在训练过程中，每次参数更新后，上层网络的输出通过这层网络后，数据的分布会发生变化，导致训练困难，这就是Internal Covariate Shift。 Internal指的是深层网络内部的中间层。与其对应的是covariate shift发生在输入层，指训练数据和测试数据分布的差异性，导致网络泛化性能的降低。可以通过归一化或者白化来解决Covariate Shift。而对于Internal Covariate Shift，则..." }, { "title": "Batch-Instance Normalization（BIN）", "url": "/posts/batchinstancenorm/", "categories": "", "tags": "deep learning, algorithm, normalization", "date": "2021-08-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/batchinstancenorm论文：https://arxiv.org/abs/1805.07925Instance normalization的缺点是其完全抹去了风格信息(it completely erases style information)，其优点是能应用在风格变换（style transfer）和图像-图像变换（image-to-image translation）的场景，但是在对比度很重要的情况下（如天气分类，天空的亮度很重要），其可能会有问题。Batch-instance no..." }, { "title": "深度学习中的各种卷积", "url": "/posts/differentconv/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-07-23 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/differentconv参考网址：https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215https://zhuanlan.zhihu.com/p/257145620说明：大部分都是翻译自第一个参考网址P1. 卷积深度学习中2D卷积如下图所示，Dout个Din*h*w的卷积核分别和输入特征进行卷积，得到Dou..." }, { "title": "池化反向传播公式的推导", "url": "/posts/backpropPool/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-07-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/backpropPool参考网址：https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/http://coollwd.top/articles/2019/12/31/1577771360985.html损失函数C对当前点\\({ {x}_{ij}}\\)的导数如下\\[\\frac{\\partial C}{\\partial { {x}_{ij}}}=\\frac{\\partial ..." }, { "title": "卷积反向传播公式的推导", "url": "/posts/backpropConv/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-07-09 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/backpropConv参考网址：https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/说明：本文未考虑padding和strideP1. 变量定义假定输入特征为\\(M\\times N\\)，卷积核大小为\\({ {k}_{1}}\\times { {k}_{2}}\\)\\(k_{ij}^{l}\\)：第l层的卷积核的第i，j个元素\\({ {b}^{l}}\\)：第l层的偏置（特征图..." }, { "title": "神经网络反向传播公式的推导", "url": "/posts/backpropNN/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-07-08 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/backpropNNP1. 变量定义\\(w_{ij}^{k}\\)：第k层的第i个神经元和第k-1层的第j个神经元之间的权重\\(b_{i}^{k}\\)：第k层的第i个神经元的偏置\\(z_{i}^{k}\\)：第k层的第i个神经元的输入\\(a_{i}^{k}\\)：第k层的第i个神经元的输出，且\\(a_{i}^{k}=\\sigma \\left( z_{i}^{k} \\right)\\)\\({ {n}^{k}}\\)：第k层的神经元个数\\(\\sigma\\)：隐含层的激活函数L：网络总层数（最后一层为输出层，其输入..." }, { "title": "Softmax导数的计算", "url": "/posts/gradientSoftmax/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-07-03 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/gradientSoftmax假设softmax层输入特征为\\(\\mathbf{z}=[{ {z}_{1}},\\cdots ,{ {z}_{i}},\\cdots ,{ {z}_{n}}]\\)，softmax层输出特征为\\(\\mathbf{a}=[{ {a}_{1}},\\cdots ,{ {a}_{i}},\\cdots ,{ {a}_{n}}]\\)，实际标签\\(\\mathbf{y}=[{ {y}_{1}},\\cdots ,{ {y}_{i}},\\cdots ,{ {y}_{n}}]\\)，其中\\({ {..." }, { "title": "全连接层梯度反向传播的推导", "url": "/posts/backpropFC/", "categories": "", "tags": "deep learning, algorithm", "date": "2021-07-02 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/backpropFC令\\(X\\in { {R}^{M\\times D}}\\)，\\(W\\in { {R}^{D\\times N}}\\)，全连接层\\(Y=XW\\in { {R}^{M\\times N}}\\)，其中\\({ {y}_{ij}}=\\sum\\limits_{k=1}^{D}{ { {x}_{ik}}\\centerdot { {w}_{kj}}}\\)，如下图所示。图1其中\\(X=\\left[ \\begin{matrix} { {x}_{11}} &amp;amp; \\cdots &amp;a..." }, { "title": "（原）faster rcnn的tensorflow代码的理解（未添加）", "url": "/posts/fasterRCNNcode/", "categories": "", "tags": "deep learning, algorithm, detection", "date": "2018-11-30 16:00:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/fasterRCNNcode" }, { "title": "ubuntu中将文件夹打包成iso的命令", "url": "/posts/CreateIsoInUbuntu/", "categories": "", "tags": "linux", "date": "2018-03-14 15:20:00 +0800", "snippet": "转载请注明出处：https://darkknightzh.github.io/posts/CreateIsoInUbuntu原始cnblogs网址：http://www.cnblogs.com/darkknightzh/p/8564483.html参考网址：https://zhidao.baidu.com/question/2203263841064787548.htmlhttps://zhidao.baidu.com/question/680880446035239332.htmlhttp://man.linuxde.net/mkisofs要将某个文件夹打包成iso，减少硬盘中的文件数..." } ]
