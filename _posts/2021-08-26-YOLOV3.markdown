---
layout: post
title:  "YOLOv3: An Incremental Improvement"
date:   2021-08-26 16:00:00 +0800
tags: [deep learning, algorithm, detection]
pin: true
math: true
---

<style> h1 { border-bottom: none } </style>

转载请注明出处：

<https://darkknightzh.github.io/posts/YOLOV3>


论文：

<https://arxiv.org/abs/1804.02767>

官方代码：

<https://pjreddie.com/darknet/yolo/>


YOLOv3是对v2版本的改进，做了一些小的修改，使其性能更好。


## **边界框预测**

和YOLO9000一样，使用k-means确定的候选框形状作为anchor。网络预测每个边界框的
$${ {t}_{x}}$$
，
$${ {t}_{y}}$$
，
$${ {t}_{w}}$$
，
$${ {t}_{h}}$$
这4个坐标。如果当前目标所在网格距离图像左上角
$$\left( { {c}_{x}},{ {c}_{y}} \right)$$
，边界框先验的宽高为
$${ {p}_{w}}$$
，
$${ {p}_{h}}$$
，则预测结果为：

$${ {b}_{x}}=\sigma \left( { {t}_{x}} \right)+{ {c}_{x}}$$

$${ {b}_{y}}=\sigma \left( { {t}_{y}} \right)+{ {c}_{y}}$$

$${ {b}_{w}}={ {p}_{w}}{ {e}^{ { {t}_{w}}}}$$

$${ {b}_{h}}={ {p}_{h}}{ {e}^{ { {t}_{h}}}}$$

训练阶段使用均方误差损失。如果用于坐标预测的GT某个真值为
$${ {\hat{t}}_{*}}$$
，使用GT值（从GT框计算得到）减去预测值
$${ {\hat{t}}_{*}}-{ {t}_{*}}$$
计算梯度。通过倒置上述公式，能很容易得到GT值。实例如图1所示。
 
![1](/assets/post/2021-08-26-YOLOV3/1prediction.png)
_图1_

YOLOv3使用逻辑回归计算每个边界框的objectness分数（GT框和候选框的IOU，即其是目标的分数，因为和GT框的IOU越大，其是目标的可能性越大）。如果某个先验框和GT框的重叠比其他先验框重叠都大，该值为1。如果某个先验框和GT框重叠不是最高，但超过了阈值0.5，则忽略该预测。本文每个GT框只分配一个先验框。如果某个先验框没有分配给GT框，则只计算其objectness（该框为候选框，计算其和GT框和IOU），不计算其坐标及类别预测的损失。


## **类别预测**

每个预测框使用多标签分类的方式预测该框包含的目标类别。该文不使用softmax因为其性能不好。训练阶段使用二值交叉熵（binary logistic）损失。好处是在Open Images Dataset数据库，标签会重叠（如“女人”和“人”），softmax认为每个框仅有一个类别，此时不成立。


## **多尺度预测**

YOLOv3使用3个不同尺度（32倍下采样，16倍下采样，8倍下采样）的特征预测目标框、目标objectness、目标类别。在COCO数据库上最后一个尺度（32倍下采样）预测3个目标（4个位置偏移、1个objectness、80个目标类别），因而输出尺寸为N\*N\*[3\*(4+1+80)]，N为特征图宽高。

之后将之前2层的特征上采样2倍，并和16倍下采样层的特征拼接。这样可以从上采样层得到更有意义的语义信息，从之前层得到更精细的纹理特征（finer-grained information）。在增加一些卷积层处理这些信息，并预测宽高增加一倍的类似张量。

重复上面过程一次，得到8倍下采样层的预测结果。

该文使用k-means来确定目标框的先验知识。该文随意的在3个尺度上选择了9个聚类结果，COCO上9个聚类尺寸为：(10 13)，(16 30)，(33 23)，(30 61)，(62 45)，(59 119)，(116  90)，(156  198)，(373 326)。


## **特征提取器**
该文使用新提出的Darknet-53作为特征提取器，其包括53个卷积层，如图2所示。

![2](/assets/post/2021-08-26-YOLOV3/2details.png)
_图2_


## **训练**
未使用难例挖掘或类似算法。


## **无效的尝试**

**① 预测预测框的偏移**：该文尝试使用常规的anchor预测机制，直接使用线性激活预测框宽高倍数的x和y的偏移。该方法降低模型稳定性，无法工作。

**② 预测x和y坐标时使用线性而不是逻辑函数**：该文尝试使用线性激活函数代替逻辑函数直接预测x和y的偏移。mAP会降低几个点。

**③ Focal loss**：Focal loss会使mAP降低2个点。

**④ 双IOU阈值**：Faster R-CNN训练阶段使用2个IOU阈值。如果预测框和GT框的IOU超过0.7，则认为是预测框正样本，在[0.3, 0.7]之间忽略，和所有GT框的IOU低于0.3则认为该预测框是负样本。该文尝试了类似的策略，但是效果不好。

该文认为，上述这些方法经过进一步调整后，也可能会有更好的结果。
