---
layout: post
title:  "SSD Single Shot MultiBox Detector(代码未添加)"
date:   2021-08-23 16:00:00 +0800
tags: [deep learning, algorithm, detection]
pin: true
math: true
---

<style> h1 { border-bottom: none } </style>

转载请注明出处：

<https://darkknightzh.github.io/posts/SSD>

论文：

<https://arxiv.org/abs/1512.02325>

第三方pytorch代码：

<https://github.com/amdegroot/ssd.pytorch>


## P1. 简介

SSD（Single Shot MultiBox Detector）由W. Liu等人于2015年提出，比之前的SOTA的一阶段的检测算法YOLO更快，切更准确，同时和二阶段的检测算法，如Faster R-CNN准确度相近。

它相比起YOLO v1 主要的改进点在于两个方面：1. 利用了先验框（Prior Box）的方法，预先给定缩放倍数和宽高比。2. 多尺度（multi-scale）预测，即对CNN 输出的后面的多个不同尺度的特征图都进行预测。

- SSD和核心是在特征图上使用小的卷积核，对固定数量的默认框，预测相应的目标类别的分数和目标框偏移。

- 为了检测精度，使用多尺度对及不同比例来监测目标。

- 端到端训练，即便在低分辨率图像上也能活的比较好的性能，进一步提高了速度和准确率之间的平衡。

- 实验结果好。

如图1，狗的尺寸较大，因此用到了更靠后的feature map（越靠后所代表的原图中的比例越大），而猫的尺寸较小，用的是前面的feature map。同时，还要适配各自的长宽比。

![1](/assets/post/2021-08-23-SSD/1ssd.png)
_图1 ssd结构（a）训练阶段SSD只需要输入图像和每个目标的真值框。不同尺度（如b中的8\*8和c中的4\*4）不同分辨率上每个位置不同长宽比默认框。每个默认框，预测形状偏移和所有目标的得分（
$$\left( { {c}_{1}},{ {c}_{2}},\cdots ,{ {c}_{p}} \right)$$
）。训练阶段，先将这些默认框和GT框匹配。例如，已经将两个默认框匹配到了猫，一个默认框匹配到了狗（由于目标大小不同，因而可能在不同分辨率上匹配到的），这些框被看成正样本，其他框则是负样本。模型使用定位损失（如Smooth L1）和置信损失（如Softmax）的加权和。_

说明：默认框：default boxes 。GT框：ground truth boxes


## P2. SSD

### P2.1 模型

SSD主要包括骨干网络和额外的网络结构。

**多尺度特征图**：骨干网络：截断的VGG16到Conv5_3层。在截断的VGG16之后加上了一些卷积层，作为多尺度特征图。

**卷积预测**：在VGG16之后增加的每个卷积层，都能得到固定数量的检测结果。如图2中SSD结构的右侧。对于p通道的m\*n大小的特征层，通过3\*3\*p的小的卷积核可以在每个m\*n的位置预测分类的分数及和默认框坐标的偏移。

多尺度特征图作为特征金字塔，好处如下：① 特征层越高，具有的语义信息越丰富，充分利用不同级别的特征，要优于只在最后一层进行检测效果。② 特征层从低到高，感受野由小到大，可用于检测不同尺寸的目标。

![2](/assets/post/2021-08-23-SSD/2compare.png)
_图2_

**默认框和长宽比**：将一系列默认边界框和每个特征图单元关联，因而每个默认框和相应的特征图单元的位置是固定的。在每个特征图单元上，预测和默认框的偏移，以及每个类别的分数。具体来说，对于每个位置中的k个框（k是每个位置有不同纵横比，所以有k个框），分别计算c个类别得分和4个和默认框的坐标偏移，这样m\*n的特征图上的每个位置共(c+4)kmn个输出。如图1对默认框进行了解释。默认框类似于Faster R-CNN中的anchor boxes，不过本文将默认框应用到不同分辨率的特征图上。

### P2.2 训练

训练包括选择用于检测的尺度和默认框的集合，以及难例挖掘和数据扰动策略。

**匹配策略**：训练阶段需要确定那个默认框对应一个GT框并训练模型。对于每个gt box，本文选择随着位置、比例、尺度上而变换的多个default box。具体匹配策略：先将IoU最高的GT框匹配给默认框，这样保证每一个GT框与唯一的一个默认框对应起来。而后将IoU超过阈值0.5的默认框匹配到GT框。这种方式可以简化训练问题，允许网络对于和GT框重叠的多个默认框都可以预测到比较高的分值，而不必强制最大重叠的预测高分值

**损失函数**：令
$$x_{ij}^{p}=\left\{ 0,1 \right\}$$
代表第i个默认框和第j个GT框的第p个类别是否匹配的标志。通过以上的匹配策略，
$$\sum\limits_{i}{x_{ij}^{p}}\ge 1$$
（对于第j个GT框，一定分配了至少1个默认框）。模型使用定位损失（loc）和分类损失（conf）的加权和：

$$L\left( x,c,l,g \right)=\frac{1}{N}\left( { {L}_{conf}}\left( x,c \right)+\alpha { {L}_{Loc}}\left( x,l,g \right) \right) \tag{1}$$

其中N为匹配到的默认框的数量。如果N=0，设置损失为0。
$$\alpha $$
为权重，通过交叉验证，设置为1。定位损失为预测框（l）和GT框（g）之间的Smooth L1 loss。和FasterR-CNN类似，本文和默认框（d）的中心偏移（cx，cy）和宽（w）高（h）。

$$\begin{align}
  & { {L}_{Loc}}\left( x,l,g \right)=\sum\limits_{i\in Pos}^{N}{\sum\limits_{m\in \left\{ cx,cy,w,h \right\}}{x_{ij}^{k}smoot{ {h}_{L1}}\left( l_{i}^{m}-\hat{g}_{j}^{m} \right)}} \\ 
 & \hat{g}_{j}^{cx}=\left( g_{j}^{cx}-d_{i}^{cx} \right)/d_{i}^{w} \quad \quad  \quad\hat{g}_{j}^{cy}=\left( g_{j}^{cy}-d_{i}^{cy} \right)/d_{i}^{h} \\ 
 & \hat{g}_{j}^{w}=\log \left( \frac{g_{j}^{w}}{d_{i}^{w}} \right) \quad \quad  \quad \quad\quad \hat{g}_{j}^{h}=\log \left( \frac{g_{j}^{h}}{d_{i}^{h}} \right) \\ 
\end{align} \tag{2} $$

其中g为GT框，d为默认框，
$$\hat{g}$$
为GT框和默认框的偏移，l为预测框。此处为拟合坐标偏移，即l为拟合的坐标偏移，期望预测的坐标偏移和实际的坐标偏移尽可能接近。

置信度损失为多类别的Softmax loss（c）：

$${ {L}_{conf}}\left( x,c \right)=-\sum\limits_{i\in Pos}^{N}{x_{ij}^{p}\log \left( \hat{c}_{i}^{p} \right)}-\sum\limits_{i\in Neg}{\log \left( \hat{c}_{i}^{0} \right)},\text{   }\hat{c}_{i}^{p}=\frac{\exp \left( c_{i}^{p} \right)}{\sum\nolimits_{p}{\exp \left( c_{i}^{p} \right)}} \tag{3}$$

**对默认框选择尺度和长宽比**：本文使用低层和高层特征进行检测。图1显示了算法中用到的2个特征图（8\*8和4\*4），实际上会使用更多特征图。

不同层的特征图有不同的感受野。假定要使用m个特征图用于预测，则每个特征图上默认框的尺度如下：

$${ {s}_{k}}={ {s}_{\min }}+\frac{ { {s}_{\max }}-{ {s}_{\min }}}{m-1}\left( k-1 \right),\text{   k}\in \left[ 1,m \right] \tag{4}$$

其中
$${ {s}_{\min }}=0.2$$
，
$${ {s}_{\max }}=0.9$$
，代表着最低层缩放0.2倍，最高层特征缩放0.9倍（此处指不同层默认框缩放不同倍数。最低层特征图较大，缩放倍数更小，更易于检测小目标；最高层特征图较小，缩放更倍数大，不会使得缩放后目标太小），中间层进行相应的归一化。使用不同宽高比的默认框，如
$${ {a}_{r}}=\left\{ 1,2,3,\frac{1}{2},\frac{1}{3} \right\}$$
。可以计算每个默认框相应的宽（
$$w_{k}^{a}={ {s}_{k}}\sqrt{ { {a}_{r}}}$$
）和高（
$$h_{k}^{a}={ { {s}_{k}}}/{\sqrt{ { {a}_{r}}}}\;$$
）。对于宽高比为1的默认框，额外增加一个缩放倍数为
$$s_{k}^{'}=\sqrt{ { {s}_{k}}{ {s}_{k+1}}}$$
的默认框，因而特征图每个位置共6个默认框。每个默认框的中心设置为
$$\left( \frac{i+0.5}{\left| { {f}_{k}} \right|}\frac{j+0.5}{\left| { {f}_{k}} \right|} \right)$$
，其中
$$\left| { {f}_{k}} \right|$$
为第k个正方形特征图的大小，
$$i,j\in \left[ 0,\left| { {f}_{k}} \right| \right)$$
。当然也可以根据实际数据库设计默认框。

通过结合不同特征图上所有位置不同尺度和不同宽高比的所有默认框，可以得到各种各样的预测，能否覆盖各种各样目标的大小和形状。如图1中，狗在4\*4特征图上匹配到了默认框，但是在8\*8特征图上没有匹配到任何默认框。因而训练阶段在8\*8特征图上被认定为负样本。

**难例挖掘**：匹配策略之后，大部分默认框都为负样本，切负样本数量很高。导致训练阶段正负样本不均衡。本文对每个默认框的置信度进行排序，并使用最高的置信度，确保正负样本比例为1:3。这样能更快收敛，且训练更稳定。

**数据扰动**：为了是模型对不同大小和形状的目标更稳健，每张训练图像通过一下方式随机采样：

① 使用整张原始图像

② 使用图像的一个子块，保证目标和子块最小的IoU为0.1,0.3,0.5,0.7,0.9

③ 随机采样一个子块

采样的子块大小是原始图像大小的[0.1, 1]倍之间，采样宽高比为0.5到2之间。经过以上步骤之后，每个子块缩放到固定大小，并且以0.5的概率水平翻转，并使用<https://arxiv.org/abs/1312.5402>中的一些图像调整方法。

**注意**：训练阶段会滤除和gt box的IoU小于阈值的，将这些设置为背景。而后难例挖掘，不会进行nms。难例挖掘时，先得到正样本数量，而后通过对预测的负样本概率进行排序，得到概率较大的，同时保证正负样本比例为1:3，使用这些正负样本计算分类损失。另一方面，只对正样本计算定位损失。

测试阶段对检测结果进行nms，去除太近的框。

## P3. 代码

之后补全
